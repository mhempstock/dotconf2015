"Session_ID",breakout,description,endTime,industries,location,products,role,skillLevel,solutions,speakers,startDate,startTime,title,track,trackTitle,type
139,19,"Join Chris Letterman, CISO, State of Alaska to hear him discuss how to turn machine data - the definitive record of all the activity and behavior of your users, transactions, applications, servers, networks and mobile devices - into security intelligence. 
Attendees will learn the following: 
- What led the State of Alaska to moving from legacy SIEM to implementing Splunk
- How the State of Alaska uses machine data to achieve operational-level visibility
- How to enable data-driven decisions to improve your agency's security posture 
- How to free up security analysts' time by increasing efficiencies across security operations 
- Lessons learned and plans for the future

","2015-09-24  14:45","{""name"":""Public Sector""}","118 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Chris Letterman"",""title"":""CISO, State of Alaska - Department of Administration""}","2015-09-24","2015-09-24  14:00","Turning Machine Data into Security Intelligence","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
166,19,"This talk will highlight how any organization can leverage Splunk to assist in the enhancement of their security awareness program. It will demonstrate how Splunk can be used by teams to analyze the effectiveness of their awareness programs while highlighting areas of improvement before, and after, training has provided to staff. Furthermore, the session will provide tips to attendees on how to incorporate Splunk directly into their security awareness training materials.","2015-09-24  14:45","{""name"":""Technology""}","319 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Josh Diakun"",""title"":""Managing Partner, Discovered Intelligence""}","2015-09-24","2015-09-24  14:00","Using Splunk to Enhance, And Prove, Your Security Awareness Programs","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
167,19,"Find out how PostFinance, Switzerland's third-largest retail bank, grew from using Splunk for log management to providing machine data-based services to a wide audience, including business applications. The session will provide a short overview of the Splunk environment at PostFinance and then focus on two use cases: 1. Business Support: The application support team has moved from using database exports and excel to create their monthly reports, to being able to recognize possible fraud cases and create any report a manager asks for on the fly. 2. Fraud Detection: Our online security team uses Splunk to survey the biggest online banking portal in Switzerland and to react in real time against threats or possible attacks. To end the session, I will take a quick look at the key success factors for implementing Splunk at PostFinance.","2015-09-24  14:45","{""name"":""Financial Services""}","320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Patrick Hofmann"",""title"":""Head of IT Infrastructure, PostFinance Ltd""}","2015-09-24","2015-09-24  14:00","How Splunk Connects Business and IT at Swiss Bank PostFinance Ltd","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
158,18,"Graphmasters has created a collaborative routing engine for its app Nunav. Its Swarm optimization algorithm distributes vehicles ideally on the streets, finds the optimal route for individuals and can potentially double traffic flows.
As part of this solution, the team at Graphmasters uses Splunk Enterprise for real-time and historical data analytics of vehicle data, like location and speed. In this session, we will show live traffic feeds and demonstrate how cars on the road are turned into machine data sources. We will explain how you can design advanced filtering and prediction techniques in Splunk software and validate with complementary prototyping tools. Finally, we will demonstrate how Splunk software is used for system performance analytics and auditing to perform QA of routing strategies.","2015-09-24  13:45","{""name"":""Manufacturing""}
{""name"":""Technology""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}
{""name"":""Data Science""}","{""name"":""Sebastian Heise"",""title"":""COO and Founder, Graphmasters GmbH""}","2015-09-24","2015-09-24  13:00","Splunking the Swarm at Graphmasters","Internet of Things","Internet of Things ","Breakout Session"
110,18,"Sierra-Cedar, Inc. delivers industry-focused client success by providing consulting, technical, and managed services for the deployment, management, and optimization of next-generation applications and technology. They have complemented the Splunk App for Enterprise Security with the Splunk App for Stream to assist with the detection of malicious activity. The wire data that is captured from the Splunk App for Stream provides additional insight into network traffic that was previously not being captured.
This session will discuss Sierra-Cedar's current deployment, strategic directions, and how they are using the Splunk App for Enterprise Security with the Splunk App for Stream. The speaker will discuss and demonstrate how Sierra-Cedar provides solutions to meet the needs of the Security team, IT operations, and their clients.","2015-09-24  13:45","{""name"":""Technology""}","118 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}
{""name"":""Splunk App for Stream""}","{""name"":""Administrator""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}
{""name"":""Deploying Splunk""}","{""name"":""Robert Miller"",""title"":""Manager - Corporate Security, Sierra-Cedar, Inc.""}","2015-09-24","2015-09-24  13:00","Sierra-Cedar's Best Practices for Building a Security Operations Center","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
160,18,"A session on Splunk indexing and search performance analysis under various conditions and environments (physical vs. virtual). Focus will be around debunking common misconceptions and presenting best practices.","2015-09-24  13:45",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Advanced ",,"{""name"":""Dritan Bitincka"",""title"":""Principal Solutions Architect, Splunk""}","2015-09-24","2015-09-24  13:00","Notes on Optimizing Splunk Performance",Deploying,"Deploying ","Breakout Session"
162,18,"This session will highlight a real-world program that leverages Splunk searches to detect malicious insiders and privileged account abuse. It will also teach basic search building blocks that will help attendees identify other potentially harmful activities occurring in their organization. The session will cover very specific examples of what insider threats look like in machine data across several industries, and will also include a live demo of portions of the Splunk App for Enterprise Security that detect insider threats and anomalous user activity. ","2015-09-24  13:45","{""name"":""Financial Services""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Derek Vadala"",""title"":""CISO, Moody's Corporation""}
{""name"":""Joe Goldberg"",""title"":""Sr. Manager, Security Marketing, Splunk""}","2015-09-24","2015-09-24  13:00","How to Use Splunk to Detect Malicious Insiders","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
161,18,"Software Defined Networking (SDN) can be a powerful tool to help your network adapt to changing conditions. However, deploying SDN does not necessitate sweeping changes to your networking infrastructure or require new skillsets for your staff. 
Splunk already provides a powerful Operational Intelligence and analytics platform. When combined with a controller, it becomes a powerful SDN application that automatically acts on this intelligence to provide greater operational flexibility and security. 
This session presents and demonstrates a system using Splunk and the Cisco Open SDN Controller for steering large data flows around firewalls and other devices that could disturb their performance while actively blocking threats.","2015-09-24  13:45","{""name"":""Technology""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Steven Carter"",""title"":""Architect, Cisco Systems""}
{""name"":""Friea Berg"",""title"":""Alliances Manager, Splunk""}","2015-09-24","2015-09-24  13:00","Event-Driven SDN with Splunk and Cisco's Open SDN Controller","IT Operations","IT Operations ","Breakout Session"
159,18,"Discover how Gatwick Airport uses Splunk Cloud to gain a real-time view of the performance of  terminals and the airfield, ensuring a high degree of efficiency for our record-breaking 925 daily flights and 38 million annual passengers?all off one strip of Tarmac. This session covers:
1 ? How we combine historical fact with ""in the moment"" data and events to predict success or failure, enabling the operation to prevent issues before they occur
2 ? How the performance dashboards we developed help us support other organisations (e.g., airlines and ground handlers) to improve their performance
3 ? How we moved from ""how did we do?"" to ""how are we doing?"" and are on the edge of answering ""How will we do?""
4 ? Plans for the future: tracking travel disruption, predicting passenger flow and getting real-time feedback via social media monitoring 
5 ? Why a cloud solution gives us the agility and scalability to achieve what we need.","2015-09-24  13:45","{""name"":""Travel and Transportation""}","114 (Level 1) ","{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Customer Success Story""}","{""name"":""Kendrick Tugwell"",""title"":""Lead IT Development Specialist, Gatwick Airport""}
{""name"":""Joe Hardstaff"",""title"":""Business Systems Design Authority, Gatwick Airport""}","2015-09-24","2015-09-24  13:00","Driving Efficiency With Splunk Cloud at the Busiest Single Runway Airport in the World",Cloud,"Cloud ","Breakout Session"
157,18,"Uber and Electricity?what do they have in common? Their prices are based on supply and demand. How that price is determined varies significantly, as anyone who has tried to use Uber on New Year's Eve or around an epic Boston snowstorm can tell you. Imagine if electricity was priced based on how many other people were using it? It turns out electricity pricing actually is done this way!
In this presentation, we'll learn about the pricing models used by Uber for surge pricing, as well as the electrical grid where charges are based on usage during peak periods (such as a hot summer day). Through the construction of a Splunk app and custom inputs, we'll leverage Splunk to collect and analyze some big data for Uber and electricity price data. We'll use the resulting analytics to show similarities and differences between the models.","2015-09-24  13:45","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Advanced ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IoT and Industrial Data""}
{""name"":""Data Science""}
{""name"":""Customer Success Story""}","{""name"":""James Nichols"",""title"":""Principal Engineer, Cloud Architect, Splunk Evangelist, EnerNOC, Inc.""}","2015-09-24","2015-09-24  13:00","Building a Splunk App to Look at Dynamic Pricing for Uber and the Electrical Grid","Business Analytics","Business Analytics ","Breakout Session"
156,17,"Discussion on our use of Splunk to normalize data feed it into ""models"" and pipe the output back into Splunk for additional analysis. Also explores extending the Splunk Query Language.","2015-09-24  12:45","{""name"":""Manufacturing""}
{""name"":""Technology""}","320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Greg Hrebek"",""title"":""Director of Engineering, New York Air Brake""}","2015-09-24","2015-09-24  12:00","Recursive Splunking--Building a Data Rube Goldberg Machine with Splunk","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
154,17,"As Splunk becomes a single source of truth for all machine data, it's important to provide a mechanism to safeguard and verify the integrity of the data being indexed. 
In the next version of Splunk, we introduce a new feature that lets users to verify the integrity of indexed raw data on demand, especially for auditing/legal/compliance purposes. The proposed solution catches any tampering made to the raw data and reports it. 
This session covers the following about this topic:
1) What is this new clustered index integrity check?
2) Why is it required?
3) How does it work?
4) What is it aiming to solve?
4) Recommended best practices","2015-09-24  12:45",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Security Analyst""}
{""name"":""CIO""}
{""name"":""CISO""}","Advanced ","{""name"":""Big Data""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Dhruva Bhagi"",""title"":""Software Developer, Splunk, Splunk""}","2015-09-24","2015-09-24  12:00","Clustered Index Integrity Check","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
164,,,"2015-09-24  12:45",,"111-112 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-24","2015-09-24  12:00",,,"Security,Compliance and Fraud ",
155,17,"This presentation covers integrating the vFeed project into Splunk to enrich vulnerability data, identify vulnerabilities with known exploits, and prioritize vulnerability remediation. Deploy the jOVAL SCAP scanner with Splunk software and measure compliance with hundreds of hardening scripts available from the National Checklist Program Repository. Learn how to integrate the Collective Intelligence Framework into Splunk software and automate threat intelligence lookups for IPs, domain names, URLs and file hashes.
Attendees will see how ARP data from network switches can be easily ingested and used to launch dynamic vulnerability scans with tools like Nessus, Qualys or OpenVAS. Honeypots are one of the most under-utilized tools by security professionals. Splunk software can be used to easily deploy a distributed network of honeypots. The presentation concludes with a discussion of using Argus and Splunk software for performing security analysis of network flows.","2015-09-24  12:45","{""name"":""Technology""}","319 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Craig Merchant"",""title"":""Senior Security Architect, Oracle""}","2015-09-24","2015-09-24  12:00","Affordable Security: Making the Most of Free Tools and Data With Splunk","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
153,17,"What are the differences between add-ons and apps?
We'll answer this question as part of a presentation revealing best practices for building add-ons with a focus on ensuring that your efforts meet the goals of your add-on, whether they be for internal use or posted on Splunkbase. 
We will discuss best practices as they relate to building an add-on, including ensuring that it is Common Information Model (CIM) compliant (to facilitate data exploration and use with CIM-compatible apps), testing the add-on, and more.
We will reference online resources, while revealing best practices worth adopting and providing caution of common pitfalls that may be avoided. Tools that make the task of building, testing and maintaining an add-on much easier will be covered as well.","2015-09-24  12:45",,"Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Best Practices""}","{""name"":""Brian Wooden"",""title"":""Senior Manager of Security Add-Ons, Splunk""}
{""name"":""Jack Coates"",""title"":""Director, Product Management, Splunk""}","2015-09-24","2015-09-24  12:00","Add-On Best Practices Check Tool",Developing,"Developing ","Breakout Session"
143,16,"Pacific Northwest National Laboratory (PNNL) uses Selenium synthetic transaction tests built in Python to monitor hosted websites. These act as a user running a real browser to visit sites and perform a set of steps. Tests are run and captured using the Universal Forwarder to gather critical data.

While these tests have been extremely valuable, manually creating tests for over 200 websites was very time consuming and difficult to maintain. Splunk to the rescue! We created a report using web logs of all the websites hosted by PNNL, grouped by server and sorted by highest traffic. Using the Splunk SDK for Python, we pulled this report and dynamically created Selenium tests that run every five minutes and test each site on the list.

Using Splunk gave us the opportunity to create a custom app that combines these synthetic transactions with our existing web logs. Now we can spot error trends and availability issues many times before our customers are even affected.","2015-09-24  12:00","{""name"":""Public Sector""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Justin Brown"",""title"":""IT Engineer, Pacific Northwest National Laboratory""}","2015-09-24","2015-09-24  11:15","Using Web Logs in Splunk to Dynamically Create Synthetic Transaction Tests for Website Monitoring","Application Delivery","Applications Management ","Breakout Session"
146,16,"Rakuten has many Internet services, including one of the biggest e-commerce sites in Japan for eReading, travel, as well as financial services. To support these services, there are many operational teams. We are providing ""Splunk as a Service"" (SPaaS) which is a big Splunk platform for all the teams so that they can use Splunk freely. In this session, we will show some challenging points for deploying SPaaS, such as best practice for managing cluster, operational improvement using Splunk's API, and tips for expanding the Splunk platform globally. In addition, we will introduce our real Splunk use cases. This part will cover what our problems in each team were, and how Splunk solved it.","2015-09-24  12:00","{""name"":""Retail""}
{""name"":""Technology""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Customer Success Story""}
{""name"":""Deploying Splunk""}","{""name"":""Keisuke Noda"",""title"":""Data Store Platform Administrator, Rakuten, Inc.""}
{""name"":""Takeshi Suzuki"",""title"":""Security Operations Group Manager, Rakuten, Inc.""}","2015-09-24","2015-09-24  11:15","Splunk as a Service at Rakuten",Deploying,"Deploying ","Breakout Session"
148,16,"Proper use of Threat Intelligence, in many cases, has a direct correlation with the amount of time it takes for your team to detect, respond to, and remediate a threat. In addition, threat intelligence providers often deliver very little, if any, context or attribution around their Intel. This makes it difficult for an analyst to determine if a match against a given feed is associated with a commodity or APT-based threat. The inability to make this distinction alone can have serious implications to a company. This discussion will focus on the role Threat Intelligence plays in an active breach investigation and how the new Threat Intelligence Framework in Splunk App for Enterprise Security can be used to fulfill this role. The audience will be walked through a simulated breach and shown how intel gleaned from compromised systems is used to assist in investigations. Attendees can expect to gain a rudimentary understanding of how they can begin managing their own threat intel for use in active or future investigations.","2015-09-24  12:00",,"118 (Level 1) ","{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Brian Luger"",""title"":""Software Engineer, Security, Splunk""}","2015-09-24","2015-09-24  11:15","Managed Threat Intelligence in the Splunk App for Enterprise Security","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
149,16,"Finanz Informatik (FI) is the IT service provider for approximately 416 German saving banks, with up to 124 million bank accounts. 
Finanz Informatik uses Splunk to comply with both internal requirements and external regulations to control the access to customer data. Learn how Finanz Informatik started with Splunk to build a centralized SIEM platform across the mainframe, network, Unix and Windows environments. Get an overview of how Finanz Informatik uses Splunk for compliance requirements. This session will cover how Finanz Informatik designed the architecture, the challenges we faced and the solutions we have implemented. 
We will present our monitoring, automated deployment and release management for Splunk in a complex, heterogeneous IT environment.","2015-09-24  12:00","{""name"":""Financial Services""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""CISO""}
{""name"":""Security Analyst""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Dirk Hille"",""title"":""Security Administrator, Finanz Informatik""}
{""name"":""Michael Grabow"",""title"":""Project Manager, Finanz Informatik""}","2015-09-24","2015-09-24  11:15","Splunk at Finanz Informatik: Compliance for 124 Million Bank Accounts",Deploying,"Security,Compliance and Fraud ","Breakout Session"
145,16,"There is a lot of valuable machine data in SaaS applications, but this data goes largely untapped.  What are your users doing in the cloud? How many documents are they sharing outside the company? Who is using what SaaS application? Are there any anomalies in their cloud access behavior? 
Wouldn't it be nice to gather this SaaS machine data and correlate it with other machine data already in your Splunk environment? Of course it would! In this session, we will cover methods to get SaaS machine data into Splunk, common use cases for SaaS machine data, and how to use Splunk App for Enterprise Security as an effective cloud security analytics solution for security use cases such as cloud user activity monitoring, cloud user behavior anomaly analysis, and data leakage and exfiltration. 
After leaving this session, you will have all the tools and frameworks you need to get started Splunking your enterprise's SaaS machine data and getting better operational insights.","2015-09-24  12:00",,"114 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}
{""name"":""Splunk Cloud""}","{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Cloud Solutions""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Log Management""}
{""name"":""Application Delivery""}
{""name"":""IT Operations""}","{""name"":""Jason Conger"",""title"":""Practice Manager, Splunk""}
{""name"":""Wissam Ali-Ahmad"",""title"":""Senior Security Solutions Architect, Splunk""}","2015-09-24","2015-09-24  11:15","""I See What You're Doing Up There"" - How to Leverage SaaS Apps from Splunk to Gain Total Visibility into Your User Activity in the Cloud",Cloud,"Cloud ","Breakout Session"
147,,,"2015-09-24  12:00",,"111-112 (Level 1) ",,,"Intermediate ",,,"2015-09-24","2015-09-24  11:15",,,"IT Operations ",
150,16,"Splunk has grown from a handful of engineers to an products organization with several hundred people, from Dev and QA to Product Management and UX. We have gone from a single product to several, and from on-prem to the cloud. Despite all this, we've managed to stay nimble, shipping more in less time and more frequently.
In this talk, we will go over how Splunk does engineering, from how we plan a release, to what tools we use to keep everything on track and stable, and what we've built to help us along the way. 
We will also cover how we use Splunk ourselves to do engineering. We use a variety of tools such as JIRA, Jenkins, Git, Perforce, Bamboo and others, and Splunk is the glue that lets us tie it all together.
This is an opportunity to look behind the curtain and see how we're able to provide our customers with the improvements and innovations in the product they love. You can also learn how you can further use Splunk internally to help your engineering organization move faster.","2015-09-24  12:00",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Log Management""}
{""name"":""IT Operations""}
{""name"":""Developing""}","{""name"":""Itay Neeman"",""title"":""Sr. Engineering Manager, Splunk""}
{""name"":""Kurt Chase"",""title"":""Director, Release Engineering, Splunk""}","2015-09-24","2015-09-24  11:15","Developing at the Speed of Splunk",Developing,"Developing ","Breakout Session"
142,15,"Health claims come in many forms and formats, including standard electronic submissions, standard paper forms, faxes (in various formats), one-off formats, and in languages other than English (e.g., Tahitian). Each of these claims follows different paths into our enterprise and eventually has to enter our claims adjudication system. Tracking claims across batch file location, numerous systems hand-offs, validation systems and reviews, while knowing current status and location and maintaining timing SLAs, has been problematic. I?ll discuss how we have used Splunk to simplify this task.","2015-09-24  10:45","{""name"":""Healthcare""}","320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}
{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Stuart Sands"",""title"":""Principal Enterprise Architect, Kaiser Permanente""}","2015-09-24","2015-09-24  10:00","Tracking Health Claims Status Across Multiple Formats, Forms, Systems and Platforms (and Not Losing Any!)","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
141,15,"Over the last 12 months Splunk has created or updated over 30 new Add-Ons, covering a broad range of data sources and providing additional out-of-the-box value to users. This session will highlight what you should know about these new products, including the latest best practices and methodology behind their development. The session will then go deep on the latest
features and best-practice use cases of DB Connect ? the preferred method for connecting Splunk to relational database content.","2015-09-24  10:45",,"319 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Best Practices""}
{""name"":""Getting Data In""}","{""name"":""Jack Coates"",""title"":""Director, Product Management, Splunk""}","2015-09-24","2015-09-24  10:00","The Latest in Splunk Add-Ons--What You Should Know","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
132,15,"DevOps is a growing need among organizations to monitor the health of rapid development and integration across multiple initiatives using agile development. The DevOps platform implemented in Splunk provides the capability to seamlessly onboard any agile project by setting up data from multiple sources like source control, a staging server where continuous builds run, and the logs from integration points, such as a database, MQ and external API call. The DevOps platform provides daily status on the progress of any agile initiative to provide useful insights for identifying improvement opportunities. The dashboards and automated reports reduce the defect injection rates by up to 70% in the release process, as well as reduce the manual efforts to match reports.","2015-09-24  10:45","{""name"":""Technology""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Advanced ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Balaji Venkatachari"",""title"":""Sr Technology Architect, Infosys Ltd""}","2015-09-24","2015-09-24  10:00","Splunk for DevOps","Application Delivery","Applications Management ","Breakout Session"
133,15,"As companies start to develop their applications and send data to AWS, the need to monitor their cloud infrastructure becomes critical. Splunk offers a solution that allows these organizations a way to have visibility across their AWS Cloud infrastructure in one platform. This session will explain the different components of what can be monitored and how to collect the data in Splunk. In addition to an explanation, sample configurations will be provided to quickly set up the Splunk App to collect the available metrics from AWS (CloudTrail, Config, Cloudwatch, and more!).   This session will also cover how to create custom inputs for third party AWS vendors. If you're just starting to deploy into AWS, an AWS developer, third party vendor, or just someone who wants to get their AWS data into Splunk, this session will help you to get it done. ","2015-09-24  10:45",,"114 (Level 1) ","{""name"":""Splunk Cloud""}
{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Business Manager""}
{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Application Delivery""}","{""name"":""Kamilo Amir"",""title"":""Sr. Sales Engineer, Splunk""}
{""name"":""Matt Poland"",""title"":""Sr. Sales Engineer, Splunk""}","2015-09-24","2015-09-24  10:00","Splunking AWS for End-to-end Visibility",Cloud,"Cloud ","Breakout Session"
140,15,"Don't force your users to remember multiple usernames and passwords. Integrate Splunk software into your corporate single sign-on tool and make your users happy and your deployment more secure. 
If you have configured LDAP or Active Directory in Splunk software for a user to log in, you are only two steps away from configuring single sign-on. In this session, we will walk you through how to set up the basic single sign-on strategy with an Apache proxy. We will look at the configuration file involved both in Splunk and Apache, and how to quickly troubleshoot SSO issues.
We'll then continue the overview of SAML, configuring Splunk with your IDP using SAML authentication and showing you what happens under the hood.","2015-09-24  10:45",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Security Analyst""}","Advanced ","{""name"":""Best Practices""}","{""name"":""Nachiket Mistry"",""title"":""Sr. Software Engineer, Splunk""}
{""name"":""Rama Gopalan"",""title"":""Senior Software Engineer, Splunk""}","2015-09-24","2015-09-24  10:00","Securing Splunk With Single Sign-On and SAML","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
137,15,"According to the Verizon Data Breach Investigation Report and Mandiant's M-Trends report, it takes organizations over 200 days to detect a breach. In most cases, the breach was disclosed by a third party. This session focuses on ways to improve cyber security attack detection through the integration of the 20 Critical Security Controls into the daily activities of security operation centers.  
Attendees will be presented with alternative methods to reactionary security monitoring and cyber-attack hunting techniques.","2015-09-24  10:45","{""name"":""Technology""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}
{""name"":""CISO""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Jason Lawrence"",""title"":""Manager, Ernst and Young""}","2015-09-24","2015-09-24  10:00","Security Operations, Data Analytics and the 20 Critical Security Controls","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
152,15,"Large state agencies deal with extremely complex IT environments, making it hard to aggregate, correlate and analyze information in real time. Collaborating across the internal stakeholders that own each data set can also prove difficult.
Learn how to develop an end-to-end monitoring solution to eliminate availability issues impacting end-user productivity within agencies and disruptions to the delivery of public-facing citizen services. 
Additionally, learn how to create dashboards that provide integrated visual analytics, allowing users to visually interact with their data to better collaborate and share results, customized for each group of key stakeholders.
The ability to transform raw data into visually meaningful and useful information will allow your agency or organization to deliver timelier triage, determine root cause faster, decrease MTTR from hours to minutes and become proactive in avoiding outages. ","2015-09-24  10:45","{""name"":""Public Sector""}
{""name"":""Technology""}
{""name"":""Manufacturing""}","120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Business Analytics""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Calvin Smith"",""title"":""Cyber Technologist, Solutions Architect and Project Lead, Northrop Grumman""}
{""name"":""Michael Rodriguez"",""title"":""Engineer, Northrop Grumman""}","2015-09-24","2015-09-24  10:00","End-to-End Monitoring and Unified Performance Dashboard Within a State Agency","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
134,15,"As your Splunk Deployment grows, so does your world of Knowledge Objects - lookups, tags, eventtypes, and many more. Are you maintaining a large set of systems sending heterogeneous data into Splunk with a CIM-style layer on top to normalize accessing that data? Have you noticed a creeping slowdown of your search startup, or at least felt as if things sometimes didn't move along as fast as you'd like them to? 
In this session, we will explore common offenders, and what can trigger an explosion of complexity for Splunk to deal with (or not). Using examples derived from real-world experience, you will learn how small changes made at one end of your search-time configuration can have great impacts on the other. To accomplish this, we will peek under the hood of how Splunk translates higher-level search constructs into normalized searches, and how you can use this knowledge to your advantage.","2015-09-24  10:45","{""name"":""Technology""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}
{""name"":""Operations Manager""}","Advanced ","{""name"":""Customer Success Story""}","{""name"":""Martin Mueller"",""title"":""Consultant, Consist Software Solutions GmbH""}","2015-09-24","2015-09-24  10:00","Optimizing Splunk Knowledge Objects - A Tale of Unintended Consequences",Deploying,"Deploying ","Breakout Session"
135,15,"Over the last year, Indiana University has deployed an enterprise service utilizing Splunk in order to facilitate easier IT policy alignment for hundreds of IT departments across the eight Indiana University campuses. This discussion focuses on university IT culture, building a scalable enterprise-grade Splunk architecture, search head clustering, optimizing searches, customer onboarding, expansion of services through targeted custom app development, and everything in between. Join the team from Indiana University in a discussion about their journey.","2015-09-24  10:45","{""name"":""Higher Education""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Allen Tucker"",""title"":""Manager, HELPnet Central Systems, Indiana University""}
{""name"":""Kelly Zimmerman"",""title"":""Server Admin, Indiana University""}","2015-09-24","2015-09-24  10:00","Indiana University: Splunking Distributed Logs for IT Policy Alignment","IT Operations","IT Operations ","Breakout Session"
136,15,"In this session, we will give a demonstration of how to use Splunk App for Enterprise Security to detect two separate advanced attacks (spear phishing and watering holes), how to pivot into Enterprise Security for hunting, and then how to feed threat intelligence back into Splunk Enterprise Security. We will also show how an analyst can use Splunk in combination with other tools like malware repositories, passive DNS databases, threat intelligence sharing platforms, and dynamic malware analysis platforms to fully break down the attack, add context, and then help to find Rumsfeldian ""known unknowns"" that may still be lurking in a network.","2015-09-24  10:45",,"118 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Ryan Kovar"",""title"":""Senior Security Strategist, Splunk""}
{""name"":""Steve Brant"",""title"":""Security Strategist, Splunk""}","2015-09-24","2015-09-24  10:00","Hunting ""known unknowns"" with Splunk App for Enterprise Security","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
138,15,"Splunk dashboards and forms provide a solid framework to quickly compose static content for showing and visualizing data from search results. Tapping into the full power of SimpleXML allows you to go beyond that and build rich interactions and workflows into your dashboards without resorting to code.
In this session you'll learn how to take a rudimentary dashboard and advance it step by step to provide a rich and interactive user experience, covering hooks and building blocks available in SimpleXML, including new ones introduced in the next version of Splunk.","2015-09-24  10:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Advanced ","{""name"":""Best Practices""}
{""name"":""Visualization""}","{""name"":""Mathew Elting"",""title"":""Senior Software Engineer, Splunk""}
{""name"":""Siegfried Puchbauer"",""title"":""Senior Software Engineer, Splunk""}","2015-09-24","2015-09-24  10:00","Advanced Interactions Using SimpleXML",Developing,"Developing ","Breakout Session"
163,15,"You're the Splunk champion. You can onboard any data source, from logs to wire data to RDBMS. You can search and correlate any sourcetypes, showing how IT failures and customer activity impact revenue growth. You're a cool viz wizard, and can implement everything from bubble charts to maps to D3 custom viz. 
Your boss loves it, and keeps buying you more Splunk. Now she wants you to build a dashboard for her boss. And her boss's boss. And her boss's boss's boss, the CEO. Where do you start?
In this talk, we'll walk you through the basics of building high-level analytics reports. We'll illustrate different types of analytics personas and help you tailor your reports to their data consumption preferences. We'll talk about leading with the right questions, like ""how does this impact revenue and costs?"" instead of ""show me a count by sourcetype."" We'll share useful tips and tricks like up/down indicators to illustrate trends, and how to use predictive analytics for knockout forecasts.","2015-09-24  10:45",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""Business Analytics""}
{""name"":""Big Data""}","{""name"":""Cody Harris"",""title"":""Solutions Engineer, Splunk""}
{""name"":""Tom LaGatta"",""title"":""Data Scientist, Splunk""}","2015-09-24","2015-09-24  10:00","Delivering High-Level Analytics Reports","Business Analytics","Business Analytics ","Breakout Session"
125,14,"The Internet of Things provides an open area of research for developing new methods for Big Data analytics. Splunk already allows users to harness and analyze data with ease, but with the combination of SQL, Splunk and R, we can develop a whole new level of predictive analytics. By combining the power of these three tools, we have created algorithms that model data and predict maintenance and failures before they occur, saving hundreds of thousands of dollars over the life of the project. 
The session walks through examples of how to implement your own algorithms using the high-level statistical capabilities of R in Splunk. We will start with the essentials and build towards more innovative processes.","2015-09-23  17:45","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}
{""name"":""Public Sector""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""Big Data""}
{""name"":""IoT and Industrial Data""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Kara Tomczak"",""title"":""System Integrator, Bechtel""}
{""name"":""Claire Longo"",""title"":""Principal Research Scientist, Battelle""}","2015-09-23","2015-09-23  17:00","The Internet of Things...Predicting the Unpredictable","Internet of Things","Internet of Things ","Breakout Session"
118,14,"There are many platforms for monitoring access to patient medical information. Most are very expensive, difficult to make changes to, and require working with a third party that may not be on the same time table as you are. Splunk can fill this need at a fraction of the cost, make it easy to create new reports, and can be setup in a relatively short time period. Come see how The Vancouver Clinic achieved this using Splunk.","2015-09-23  17:45","{""name"":""Healthcare""}","120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}
{""name"":""Administrator""}
{""name"":""CISO""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Davin Studer"",""title"":""Systems Analyst, The Vancouver Clinic""}","2015-09-23","2015-09-23  17:00","Patient Privacy Monitoring with Splunk","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
127,14,"Want to take a DevOps approach to systematically manage your Splunk deployments? This talk will cover two key areas of utilizing GitHub for managing Splunk configuration files and integrating with Ansible for fully automated Splunk deployment. By managing all of your Splunk configuration files within git, you are able to control and monitor changes to the Splunk environment, and also monitor user activity. This configuration repository will then be used with Ansible to orchestrate very large Splunk deployments. In this session, we will cover the use of Splunk-specific Ansible play books that follow best practices for managing many Splunk deployments for multiple customers or business units.","2015-09-23  17:45",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Intermediate ",,"{""name"":""Sean Delaney"",""title"":""Client Architect, Splunk""}
{""name"":""Jose Hernandez"",""title"":""Director of Big Data Security Solutions, Zenedge""}","2015-09-23","2015-09-23  17:00","Splunk Configuration Management and Deployment with Ansible",Deploying,"Deploying ","Breakout Session"
128,14,"Discover how DATEV has delivered cross-departmental visibility into IT infrastructure in order to reduce major incidents and improve the service they offer to customers. This session covers useful techniques to reduce mean time to investigate (MTTI) and mean time to resolve (MTTR). In addition to monitoring servers and network devices, learn how DATEV is gaining operational insights from mainframe servers and applications with Syncsort's Ironstream and web applications.","2015-09-23  17:45","{""name"":""Technology""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Andreas Jahnke"",""title"":""Manager ITIL Event Management and Monitoring, DATEV eG""}","2015-09-23","2015-09-23  17:00","Splunk at DATEV: Reducing Incidents and Enhancing Services with Operational Intelligence","IT Operations","IT Operations ","Breakout Session"
124,,,"2015-09-23  17:45",,"118 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  17:00",,,"Applications Management ",
131,"13
13","(Bring your laptop, not a tablet, preferably a non-IE browser)
 
Join our security experts to learn how to use Splunk Enterprise Security in this special two-hour interactive, hands-on session. We?ll begin by helping you obtain your own personal Splunk Enterprise Security environment provisioned in the cloud. We'll take a brief tour through this next-generation security intelligence platform to show you some of the unique capabilities of the product, then we?ll get right into detecting advanced threats and moving through an incident response scenario. We?ll use Splunk Enterprise Security to detect an advanced threat, and then work the incident to disrupt an adversary's Kill Chain by finding the actions on intent, exploitation methods, and reconnaissance tactics used against a simulated organization. We will investigate using comprehensive data sets for full visibility across the enterprise ? including threat intelligence feeds, endpoint activity logs, e-mail logs, and web access logs. This session is a must for all security professionals! Don?t forget to bring your laptop ? and get ready to roll up your sleeves!
(Bring your laptop, not a tablet, preferably a non-IE browser)
 
Join our security experts to learn how to use Splunk Enterprise Security in this special two-hour interactive, hands-on session. We?ll begin by helping you obtain your own personal Splunk Enterprise Security environment provisioned in the cloud. We'll take a brief tour through this next-generation security intelligence platform to show you some of the unique capabilities of the product, then we?ll get right into detecting advanced threats and moving through an incident response scenario. We?ll use Splunk Enterprise Security to detect an advanced threat, and then work the incident to disrupt an adversary's Kill Chain by finding the actions on intent, exploitation methods, and reconnaissance tactics used against a simulated organization. We will investigate using comprehensive data sets for full visibility across the enterprise ? including threat intelligence feeds, endpoint activity logs, e-mail logs, and web access logs. This session is a must for all security professionals! Don?t forget to bring your laptop ? and get ready to roll up your sleeves!","2015-09-23  17:45",,"122-123--124 (Level 1) ","{""name"":""Splunk App for Enterprise Security""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Best Practices""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""James Brodsky"",""title"":""Security Subject Matter Expert, Splunk""}
{""name"":""James Brodsky"",""title"":""Security Subject Matter Expert, Splunk""}","2015-09-23","2015-09-23  17:00","Hands-On Session: Security Intelligence with Your Very Own Instance of Splunk Enterprise Security
Hands-On Session: Security Intelligence with Your Very Own Instance of Splunk Enterprise Security","Security Compliance and Anti-fraud
Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session
Breakout Session"
126,14,"More companies are looking to use Amazon Web Services to deploy new applications, migrate existing workloads, and create hybrid clouds. AWS is quickly becoming the new data center for many companies. In this discussion, we'll share how to architect Splunk Enterprise in the AWS cloud by leveraging best practices from both Splunk and AWS technologies. You'll learn how to design a highly available and resilient Splunk Enterprise that resides on the AWS cloud.","2015-09-23  17:45",,"114 (Level 1) ","{""name"":""Splunk Cloud""}
{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Application Delivery""}","{""name"":""Simeon Yep"",""title"":""Sr. Solutions Architect, Splunk""}
{""name"":""Nate Kwong"",""title"":""Sr. Sales Engineer, Splunk""}","2015-09-23","2015-09-23  17:00","Deploying Splunk on Amazon Web Services",Cloud,"Cloud ","Breakout Session"
,,,"2015-09-23  17:45",,"119 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  17:00",,,"Security,Compliance and Fraud ",
113,13,"To gain visibility of quality functions, specifically, final product test and configuration, requires the use of data historians or other types of structured relational databases that require heavy IT resources to create schemas and IT system architectures that tend to stay fixed or require change control procedures to modify.
Zebra's products have evolved over time to be sophisticated, highly configurable pieces of equipment that print barcode labels to support enterprise asset intelligence solutions. As these printer products are manufactured, the goals were to capture the time that product was tested, how it was tested and how it was configured along with any device profile that can be extracted from the device.
This discussion will focus on how Splunk software has provided visibility to the manufacturing environment by collecting test and configuration profiles at the time the item is manufactured and how Zebra is harnessing this data to drive Operational Intelligence.","2015-09-23  17:00","{""name"":""Manufacturing""}
{""name"":""Technology""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Business Manager""}
{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""IoT and Industrial Data""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Saul Llamas"",""title"":""Manufacturing Test Engineering Manager, Zebra Technologies""}","2015-09-23","2015-09-23  16:15","Using Splunk Software to Harness Zebra's Manufacturing and Device Data to Gain Visibility and Provide Operational Intelligence","Business Analytics","Business Analytics ","Breakout Session"
123,13,"If you can make dashboards?is that analytics? If you have large business problems to solve, and a tool like Splunk, how do you bring your organization from keyword searching to delivering actionable intelligence from your machine data? Do you need a math major, a statistician, a data scientist to achieve these outcomes? How does one approach data science in a business struggling to prioritize the value of big data?
These are some of the questions to be answered with a panel of highly qualified experts, including leaders and practitioners from customers, partners and Splunk. Panelists include: Mackenzie Kosut, head of technical operations with Oscar Health; Sophia Norella, Manager of Data Science also at Oscar; Michael Cormier, co-founder and CEO of Scianta Analytics; Dr. Tom LaGatta, Splunk Data Scientist; James Hodge, Big Data and Analytics Lead for Splunk in EMEA, and Manish Sainani, Principal Product Manager at Splunk, who is responsible for Machine Learning and Advanced Analytics.","2015-09-23  17:00",,"101-102 Panel Room ","{""name"":""Splunk Enterprise""}","{""name"":""Business Manager""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Data Science""}","{""name"":""Tom LaGatta"",""title"":""Data Scientist, Splunk""}
{""name"":""Hal Rottenberg"",""title"":""Developer Evangelist, Splunk""}","2015-09-23","2015-09-23  16:15","Unraveling Analytics and Data Science: An Expert Panel","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
114,13,"Many companies have started to gather vast amounts of operational and sensor data from industrial production processes, but only a few use this data to optimize productivity and business. Splunk partner Robotron leverages Splunk as a platform for mining machine data and correlating various data sources for analysis and optimization. By enriching time-series energy data with process data, Robotron enables its own energy and manufacturing customers to improve production costs and throughput while increasing sustainability and resource efficiency in production processes with up to 25% energy savings. 
Based on their domain expertise and understanding of the energy market, Robotron developed the ""eLight Energy Suite"" on top of Splunk Enterprise. It enables customers to collect and harmonize energy data with production process data (e.g. Statistical Process Control). With help of the R app, advanced data mining methods are also available to identify process weaknesses. ","2015-09-23  17:00","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""IoT and Industrial Data""}
{""name"":""Business Analytics""}","{""name"":""Phillipp Drieger"",""title"":""Sales Engineer, Splunk""}
{""name"":""Matthias Ilgen"",""title"":""Project Manager, Robotron""}","2015-09-23","2015-09-23  16:15","Save Energy with Splunk: Leverage Process and Energy Data to Optimize Industrial Processes","Internet of Things","Internet of Things ","Breakout Session"
112,13,"Wishing there was a simple way to familiarize your first time users to your Splunk deployment or Splunk app? Want an easy way to introduce the product workflow, user interface and inspire them to take next steps? Look no further! In the next version of Splunk we introduce the Product Tour Framework, image-based content tours designed to help you onboard new users more quickly.
In this session, we will demo two image-based tours and one interactive tour that ships with the next version of Splunk. We present the tour framework and go in-depth to show how Admins and App developers can create their own tours for specific business needs. We will provide best practices on creating images, composing captions and introducing complex single page applications.
Finally we will shed light on how to package tour configuration and content to start enabling your team!","2015-09-23  17:00",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Nachiket Mistry"",""title"":""Sr. Software Engineer, Splunk""}
{""name"":""Eric Bond"",""title"":""Senior UI Guy, Splunk""}","2015-09-23","2015-09-23  16:15","Onboarding with Product Tours in the Next Version of Splunk",Adopting,"Adopting ","Breakout Session"
121,13,"The ability to generate reports on a periodic schedule is one of the core features of Splunk Enterprise.
Scheduling many reports naively can lead to some getting skipped that in turn can lead to having incomplete information upon which actions are taken (or not taken).
Knowing the details of how the scheduler works can enable you to use your existing hardware resources to generate reports more effectively.","2015-09-23  17:00",,"121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}","Advanced ","{""name"":""Best Practices""}","{""name"":""Paul Lucas"",""title"":""Sr. Software Engineer, Splunk""}","2015-09-23","2015-09-23  16:15","Making The Most Of The New Splunk Scheduler","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
131,"13
13","(Bring your laptop, not a tablet, preferably a non-IE browser)
 
Join our security experts to learn how to use Splunk Enterprise Security in this special two-hour interactive, hands-on session. We?ll begin by helping you obtain your own personal Splunk Enterprise Security environment provisioned in the cloud. We'll take a brief tour through this next-generation security intelligence platform to show you some of the unique capabilities of the product, then we?ll get right into detecting advanced threats and moving through an incident response scenario. We?ll use Splunk Enterprise Security to detect an advanced threat, and then work the incident to disrupt an adversary's Kill Chain by finding the actions on intent, exploitation methods, and reconnaissance tactics used against a simulated organization. We will investigate using comprehensive data sets for full visibility across the enterprise ? including threat intelligence feeds, endpoint activity logs, e-mail logs, and web access logs. This session is a must for all security professionals! Don?t forget to bring your laptop ? and get ready to roll up your sleeves!
(Bring your laptop, not a tablet, preferably a non-IE browser)
 
Join our security experts to learn how to use Splunk Enterprise Security in this special two-hour interactive, hands-on session. We?ll begin by helping you obtain your own personal Splunk Enterprise Security environment provisioned in the cloud. We'll take a brief tour through this next-generation security intelligence platform to show you some of the unique capabilities of the product, then we?ll get right into detecting advanced threats and moving through an incident response scenario. We?ll use Splunk Enterprise Security to detect an advanced threat, and then work the incident to disrupt an adversary's Kill Chain by finding the actions on intent, exploitation methods, and reconnaissance tactics used against a simulated organization. We will investigate using comprehensive data sets for full visibility across the enterprise ? including threat intelligence feeds, endpoint activity logs, e-mail logs, and web access logs. This session is a must for all security professionals! Don?t forget to bring your laptop ? and get ready to roll up your sleeves!","2015-09-23  17:00",,"122-123--124 (Level 1) ","{""name"":""Splunk App for Enterprise Security""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Best Practices""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""James Brodsky"",""title"":""Security Subject Matter Expert, Splunk""}
{""name"":""James Brodsky"",""title"":""Security Subject Matter Expert, Splunk""}","2015-09-23","2015-09-23  16:15","Hands-On Session: Security Intelligence with Your Very Own Instance of Splunk Enterprise Security
Hands-On Session: Security Intelligence with Your Very Own Instance of Splunk Enterprise Security","Security Compliance and Anti-fraud
Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session
Breakout Session"
120,13,"Many apps have dashboards that need to run searches over millions of events before results can be displayed. Opening these dashboards can be painful as they may take minutes to populate. This is where an accelerated data model can help, as it easily speeds up searches by 50x to 100x. It is the only Splunk acceleration technology that works on all searches, but it requires a rewrite of the search processing language statements. In this session, you will learn all you need to know in order to make use of this exciting Splunk feature.","2015-09-23  17:00",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ",,"{""name"":""Helge Klein"",""title"":""Founder, vast limits GmbH""}","2015-09-23","2015-09-23  16:15","Building Your App on an Accelerated Data Model",Developing,"Developing ","Breakout Session"
115,13,"The Splunk default configuration for SSL (certificates and settings) are entirely appropriate for a trial / proof of concept.  For a production environment, security best practice, and in some cases regulatory requirements demand more.  This session will cover best practices for implementing your own SSL certificates on all Splunk channels. The right configuration and steps can provide both encryption and authentication needed for today's due diligence requirements.
This is updated material from ""Avoid the sslippery slope of default SSL"" presented at .conf 2014, updated for the latest Splunk features.","2015-09-23  17:00",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Duane Waddle"",""title"":""Security Engineer, Defense Point Security""}","2015-09-23","2015-09-23  16:15","Best Practices Configuration for Splunk SSL",Deploying,"Deploying ","Breakout Session"
94,12,"The security market is flooded with companies promising to provide cyber threat intelligence that will protect your organization from the 'bad guys.' However the amount of data and the applicability of that data in your environment make it difficult to turn data into actionable threat information.
How do you leverage Indicators of Compromise (IOCs) from many sources and turn that into actionable information in your environment? 
In this discussion, we will talk about how we turn data into knowledge and actionable countermeasures. We will explain the processes we use surrounding Splunk to turn IOCs from the threat community into tangible protection in our organizations.","2015-09-23  15:45","{""name"":""Healthcare""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Katie Winslow"",""title"":""Sr. Manager, Threat Management and Governance, Kaiser Permanente""}
{""name"":""Michael Slavick"",""title"":""Lead Security Consultant, Kaiser Permanente""}","2015-09-23","2015-09-23  15:00","Turning Indicators of Compromise into Tangible Protection","Security Compliance and Anti-fraud","Security and Compliance ","Breakout Session"
119,12,"The ongoing cyber-war has a front line and that is the endpoint. In this session, you'll learn various methods to improve endpoint security with the Splunk Universal Forwarder and with commercial endpoint solutions. You can gain critical, timely, detailed information about what's happening on your desktops, laptops, hosts, and POS systems. You can correlate this data to network, threat intel, and other data sources. You'll learn how filesystem details, processes, services, hashes, ports, registry settings and more can be used to detect attackers. This will help any organization using Splunk to greatly improve their security posture.","2015-09-23  15:45","{""name"":""Retail""}
{""name"":""Technology""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""James Brodsky"",""title"":""Senior SE/Security SME, Splunk""}","2015-09-23","2015-09-23  15:00","Splunking The Endpoint","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
111,12,"Until recently, digital content producers have had to trust the download metrics provided by third party companies?CDNs, ad servers, Podtracker, iTunes, etc. The challenge is the metrics are not collected consistently across technologies. Streaming media tracking is complicated and third-party systems are creating false impressions that need to be manually filtered.
Advertisers rely on these metrics when buying digital ad impressions. Unfortunately for the advertisers, they may be buying server pings and robot downloads.  
Learn how we used Splunk to ""normalize"" multi-technology streaming data in a CIM-compliant manner. Leveraging data model acceleration to produce a fast, unified view into crucial business metrics and identify robots saved $6K in a month. 
Understand how to analyze/normalize streaming media data and apply it to a data model using extractions, eventtypes, tags, etc. Tips and tricks to write and validate complex accelerated dashboards across different types of data.","2015-09-23  15:45","{""name"":""Media and Entertainment""}","320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Business Manager""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Alex Gitelzon"",""title"":""System Administrator, American Public Media""}
{""name"":""Jeff Kent"",""title"":""President, m-mobo""}","2015-09-23","2015-09-23  15:00","What You Think Is Real Is Not Real--Learn How Splunk Uncovered the Truth!","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
107,12,"Many use cases for Splunk benefit from the ability to maintain state for a user interaction within a Splunk App. A good example is supporting a workflow capability, marking events for later processing or for temporarily storing aggregated information. The KVStore introduced with version 6.2 provides a mechanism that supports CRUD activities on data elements that support keeping such state in an App. This session will provide an introduction to the KVStore, how to configure the KVStore in your Splunk instance and how to use it. It will also cover what its limitations are and give you a preview of what's in store for the KVStore implementation in the next major release of Splunk. ","2015-09-23  15:45",,"121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Administrator""}","Intermediate ",,"{""name"":""Stefan Sievert"",""title"":""Client Architect, Splunk""}","2015-09-23","2015-09-23  15:00","The 'State' of Splunk - Using the KVStore to Maintain App State",Developing,"Developing ","Breakout Session"
103,12,"You have SoS and Fire Brigade installed, but what about the actual data you are ingesting?is it being sourcetyped correctly? Are the appropriate props settings in place for your sourcetypes? Is line breaking happening correctly? If you struggle with these questions and more, this session is for you. 
We will cover aspects of the Data Curator app which was developed by the OSU Splunk team from methodologies used to troubleshoot and gain insight into their 2TB license from myriads of devices and data sources. This app includes a methodology to score the maturity of your data onboarding and field definition, numerous troubleshooting dashboards to highlight issues with data (i.e., timestamps, line breaking, learned sourcetypes), a sample data taxonomy, and ways to leverage your own data to show where other data you are onboarding might be mis-sourcetyped.

","2015-09-23  15:45","{""name"":""Higher Education""}","115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Mark Runals"",""title"":""Sr Security Engineer, The Ohio State University""}","2015-09-23","2015-09-23  15:00","Taming Your Data",Deploying,"Deploying ","Breakout Session"
89,12,"EnerNOC, a leading provider of Energy Intelligence Software, has a diverse application platform and a complex, quick response operational model. In this presentation we discuss how Splunk, brought in as a technical tool, became an operational godsend.
Splunk enabled operational users to have unprecedented systems data access and quickly gain insight through searches and dashboards, and with the use of alerting, made that knowledge actionable. Once Ops brought in the Dev team followed. Splunk is now one of our primary DevOps tools. 
Every organization has a wide variety of knowledge and technical competencies. Splunk becomes a focal point that helps organizations to share knowledge and reduce the need for translation. This helps us all speak the same language, and thereby ""raises all ships"" in technical literacy.","2015-09-23  15:45","{""name"":""Energy and Utilities""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}
{""name"":""Getting Data In""}","{""name"":""Grace Sumner"",""title"":""Senior Production Operations Engineer, EnerNOC""}","2015-09-23","2015-09-23  15:00","Splunk: Uniting Ops and Dev (Before DevOps was Cool)","Application Delivery","Applications Management ","Breakout Session"
109,,,"2015-09-23  15:45",,"318 (Level 3) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  15:00",,,"Splunk Enterprise/What’s New?! ",
104,12,"In this session, we will review common issues IBM mainframe operations are facing. We'll show how Splunk and Ironstream address these issues in real time and show a live demonstration of IT OpS solution, including Splunk Enterprise and Syncsort's Ironstream solution.","2015-09-23  15:45","{""name"":""Technology""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Intermediate ","{""name"":""IT Operations""}","{""name"":""Donald Marcotte"",""title"":""Director of Global Alliances, Syncsort""}","2015-09-23","2015-09-23  15:00","Splunk/Ironstream and IT Ops on z/OS","IT Operations","IT Operations ","Breakout Session"
108,12,"This session will cover information display theory and effective communication of your big data universe. By having deep knowledge of your indexed data and who your audience is, you can be successful at creating dashboards that communicate in a concise and effective manner.","2015-09-23  15:45","{""name"":""Retail""}","304-305 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Jason Hupka"",""title"":""Splunk Architect, Staples""}","2015-09-23","2015-09-23  15:00","Know Your Data, Know Your Audience","Big Data","Big Data ","Breakout Session"
106,12,"Search head clustering has a very distinct way of managing application content, settings and permissions. We'll talk about what gets replicated by the cluster automatically, and what kinds of settings are not replicated. We'll touch on the *.meta files for permissions on apps and objects, and how these might be managed by the deployer. In addition, in talking about the deployer, we'll talk about best ways to manage cluster-wide settings there as well.","2015-09-23  15:45",,"120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Intermediate ",,"{""name"":""Sanford Owings"",""title"":""Principal Consultant, Splunk""}","2015-09-23","2015-09-23  15:00","Curating User Content in the Context of Search Head Clustering",Deploying,"Deploying ","Breakout Session"
101,12,"We will discuss how Splunk adoption in UniCredit provided a life-changing way of solving old-fashioned issues with brand new and effective approaches. Not so long ago, we struggled to obtain a thorough vision and a firm grasp over our IT infrastructure and applications while trying to avoid implementing several different tools. When Splunk broke in, initially for troubleshooting purposes, we embraced its vision and grew fond of its features. Now it is the key product for many different use cases, ranging from audit, compliance and security to business analytics, application management, Operational Intelligence and advanced monitoring fields.

","2015-09-23  15:45","{""name"":""Financial Services""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Customer Success Story""}","{""name"":""Mirko Carrara"",""title"":""IT DevOps and Splunk Lead, Unicredit""}
{""name"":""Stefano Guidobaldi"",""title"":""IT System Architect, Unicredit""}","2015-09-23","2015-09-23  15:00","A Constant Evolution Towards Vision, Performance and Analytics","Business Analytics","Business Analytics ","Breakout Session"
90,11,"NCR, the largest point-of-sale (POS) provider in the U.S., has hospitality brands looking to leverage in-store purchase behavior to drive loyalty through their apps to extend customer engagement beyond brick and mortar. Leveraging QWASI's technology to create contextually relevant experiences for their loyalty customers, brands can view, measure and act on any customer event processed through the platform. Utilizing Splunk and SplunkJS, QWASI provides better insight into high volumes of event data to both measure historical engagement as well as tailor customer experience for the loyalty customers. By using QWASI's AIM to interact and communicate with customers around events like purchase, location and in app activity, brands can better understand customer behavior and the customer journey, draw attribution, and perform predictive campaigns based on real-time analysis.","2015-09-23  14:45","{""name"":""Retail""}
{""name"":""Technology""}","115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""CIO""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""Customer Success Story""}","{""name"":""Jon Thies"",""title"":""CTO, Qwasi Inc.""}
{""name"":""Scott Hall"",""title"":""Sr. Technical Solutions Manager, NCR""}","2015-09-23","2015-09-23  14:00","Where Mobile Meets In-Store and Point of Sale - Data Collides. Making Real Time Data Actionable to Drive Decisions","Business Analytics","Business Analytics ","Breakout Session"
97,11,"We have a plethora of data available with the IoT, hybrid cloud and the world of mobile. However, we often forget about the rich, insightful data of DevOps tooling that provide the mechanism for our applications to get to production.
How did the solutions get us there? Did the magic DevOps elves visit during the night? Was it Joe from Accounting? What if we could understand not only the health and status of applications, but also how they were deployed, by whom and when?
In this session, we will discover how Splunk software can provide that insight by tapping into the extensive data that drives pipelines and deployments. Also, we will investigate what problems these datasets help to solve and how you can leverage existing solutions such as Chef and Octopus Deploy.

","2015-09-23  14:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Cloud Solutions""}
{""name"":""Log Management""}
{""name"":""IT Operations""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Matthew Erbs"",""title"":""Owner, Merbla Solutions""}","2015-09-23","2015-09-23  14:00","Throw Your Future Self a Lifeline With a Little DevOps Data",Developing,"Developing ","Breakout Session"
91,11,"The KONCAR Group is an electrical, transport and energy company based in Zagreb, Croatia. Among the many companies in the group, KONCAR electrical industry builds and deploys wind turbines.
Wind turbines generate a huge amount of data about their availability, production of energy and energy losses. KONCAR previously stored this data in a SQL database and used external applications to produce various reports as well as to proactively alert when a particular wind turbine is having issues. This became extremely cumbersome as the amount of historical data kept growing.
In a successful project, INFIGO implemented Splunk as the tool for analysis and visualization of data generated by wind turbines. All complex calculations that were done before by external applications have been fully implemented in Splunk. Finally, a custom external .NET application has been developed that relies on Splunk's SDK API to produce specific PDF and Excel reports in formats requested by the customer.","2015-09-23  14:45","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}","{""name"":""Marijan Fofonika"",""title"":""Senior developer, INFIGO IS d.o.o.""}
{""name"":""Ante Martinic"",""title"":""Business Unit Director, Koncar""}","2015-09-23","2015-09-23  14:00","Splunking Wind Turbines and Keeping the Earth Green","Internet of Things","Internet of Things ","Breakout Session"
92,11,"This presentation will discuss monitoring the health of your Splunk environment with the Distributed Management Console and Splunk Health Check Overview App. The session will cover Splunk Professional Services team best practices for tuning and which key indicators to look for to ensure your environment is functioning properly.","2015-09-23  14:45",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Good for All Skill Levels ",,"{""name"":""Aaron Kornhauser"",""title"":""Sr. Professional Services Consultant, Splunk""}
{""name"":""Vladimir Skoryk"",""title"":""Sr. Professional Services Consultant, Splunk""}","2015-09-23","2015-09-23  14:00","Splunk Health Check. How is Your Environment Feeling?",Deploying,"Deploying ","Breakout Session"
93,11,"Over the years, Leidos IT has built up a portal (which was badly in need of a re-design/facelift) for management information on inventory, status, performance, logs, special reports and more. Then along came Splunk 6, and we transformed all the critical information displays into a sleek new delivery vehicle. Come and see how. 

","2015-09-23  14:45","{""name"":""Public Sector""}
{""name"":""Technology""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Intermediate ","{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Donald Mahler"",""title"":""Director Performance management, Leidos""}","2015-09-23","2015-09-23  14:00","Making Splunk Your Primary IT Information Portal","IT Operations","IT Operations ","Breakout Session"
98,11,"Splunk is a powerful platform for understanding your data. The preview of the Machine Learning Toolkit and Showcase App extends Splunk with a rich suite of advanced analytics and machine learning algorithms, which are exposed via an API and demonstrated in a showcase. In this session, we'll present an overview of the app architecture and API and then show you how to use Splunk to easily perform a wide variety of tasks, including outlier detection, predictive analytics, event clustering, and anomaly detection. We'll use real data to explore these techniques and explain the intuition behind the analytics.","2015-09-23  14:45",,"319 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}","Advanced ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Visualization""}","{""name"":""Adam Oliner"",""title"":""Principal Engineer, Splunk""}
{""name"":""Jacob Leverich"",""title"":""Principal Engineer, Splunk""}","2015-09-23","2015-09-23  14:00","Machine Learning and Analytics in Splunk","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
37,11,"This session will cover the complete strategy of utilizing Splunk Enterprise in detecting customer account takeover fraud as well as setting up automated alerts when such activity is detected.
While these measures have been implemented at a large financial services organization, the same approach can be applied to any online enterprise where it is essential to protect online customer accounts, quickly detect suspicious activity and act to prevent monetary and business losses.
The techniques described in this session generate a low level of false positives and contain efficient ways to adjust trigger thresholds within multiple metrics for specific business needs. In addition, it is tested and works really well for portals that generate up to 3,000,000-5,000,000 hits a day.","2015-09-23  14:45","{""name"":""Financial Services""}","121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Gleb Esman"",""title"":""Consultant, Financial Services Organization""}","2015-09-23","2015-09-23  14:00","Detecting Bank Account Takeover and Fraud Cyber Attacks with Splunk","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
100,11,"Are you an experienced DBA, but new to Splunk? Did your company recently buy or implement Splunk to improve Operational Intelligence or application delivery? Are you currently sorting out how this technology compares to what you are used to? Then this session was created for you.  
We'll discuss the basic architecture of Splunk, including HA strategies. Then, we will consider structured vs. unstructured data, take a look at loading data, and contrast SPL with SQL. Finally, we'll wrap up with search optimization, archiving historical data, touch on security, and exploring your alert log in Splunk.","2015-09-23  14:45",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""IT Operations""}","{""name"":""Holly Willey"",""title"":""Solutions Architect, Splunk""}","2015-09-23","2015-09-23  14:00","Intro to Splunk for Oracle DBAs","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
96,11,"Security professionals and systems administrators face the difficult challenge of protecting their networks with limited resources. This challenge is compounded by the increased use of zero-day exploits, determined adversaries and small windows between when a vulnerability is announced and exploit code is available. Microsoft's Enhanced Mitigation Experience Toolkit (EMET) and AppLocker for application whitelisting are tools which can provide valuable protection without additional software expenditures. But there's a catch: there's no console for alerting and reporting what's happening with those tools on your network.
In this discussion, we will demonstrate how you can leverage your existing investment, getting value from free tools like EMET and AppLocker by building enterprise-worthy alerting and analysis capabilities yourself. You will learn how to adapt this strategy to the unique needs of your organization. Build a console customized to show what you need to know.","2015-09-23  14:45","{""name"":""Higher Education""}
{""name"":""Nonprofit""}
{""name"":""Technology""}
{""name"":""Public Sector""}","120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Craig Lewis"",""title"":""Manager of IT Systems Engineering, Carnegie Mellon University - Software Engineering Institute""}
{""name"":""Joe Tammariello"",""title"":""Senior Systems Engineer, Carnegie Mellon University - Software Engineering Institute""}","2015-09-23","2015-09-23  14:00","Create a Console for Security Apps That Don't Have One","Security Compliance and Anti-fraud","Security Compliance and Fraud ","Breakout Session"
88,10,"The Splunk log information includes general operation and performance data, host resource usage, error and warning messages, application deployment activities, user activities, license usage, etc. A good understanding of the log messages can help users gain insights into Splunk systems to prevent or fix potential problems in operation. However, only general INFO level messages are generated in the logs by default. To troubleshoot problems, users may need to alter the logging level of different categories (Splunk modules). We will overview all Splunk log files with a focus on metrics.log, splunkd.log and splunkd_access.log. We will discuss the designated scopes of each file, cover their categories and message structures, and explain how to tune the logging level. The purpose of this presentation is to make users familiar with the log files and be able to understand the log messages in order to identify root causes during troubleshooting.","2015-09-23  13:45",,"120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}","Intermediate ","{""name"":""Best Practices""}","{""name"":""Victor Ebken"",""title"":""Software Engineer, Splunk""}
{""name"":""Xiaoyuan Li"",""title"":""Sr. Software Engineer, Splunk""}","2015-09-23","2015-09-23  13:00","Using Splunk Internal Logs for System Health Diagnosis and Troubleshooting","Splunk Classics","Splunk Classics ","Breakout Session"
P1,,,"2015-09-23  13:45",,"122-123--124 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  13:00",,,,
82,10,"It's true, big data is fascinating. It allows us to detect problems, recognize patterns, and mitigate issues. What do you do when your service or application doesn't have the volume needed for easy problem identification? Real challenges start to arise about what a true ""error"" looks like. After having the luxury of working in large volume environments such as Viacom and Tumblr, I was thrown into the challenging world of tiny data at Oscar. There are many lessons learned which are now beneficial to apply to larger environments.","2015-09-23  13:45","{""name"":""Healthcare""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Business Manager""}
{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Advanced ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""IT Operations""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Mackenzie Kosut"",""title"":""Head of Technical Operations, Oscar Health""}
{""name"":""Timothy  Faust"",""title"":""Data Scientist, Oscar Health""}","2015-09-23","2015-09-23  13:00","Hold Me Closer Tiny Data","Business Analytics","Business Analytics ","Breakout Session"
85,,,"2015-09-23  13:45",,"111-112 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  13:00",,,"IT Operations ",
83,10,"This session outlines how the City of Los Angeles, faced with tight budgets and limited security personnel, successfully implemented a data-focused approach to ensuring cybersecurity across  departments. The CISO of the City, Timothy Lee, details how the City built an Integrated Security Operations Center, analyzing 14 million+ events per day, using Splunk Cloud and the Splunk App for Enterprise Security. Lee also outlines how the City was able to accelerate its deployment by pursuing a cloud-based approach to SIEM and enhanced cybersecurity collaboration between internal and external stakeholders. ","2015-09-23  13:45","{""name"":""Public Sector""}","114 (Level 1) ","{""name"":""Splunk Cloud""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Administrator""}
{""name"":""Security Analyst""}
{""name"":""CIO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Cloud Solutions""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Tim Lee"",""title"":""CISO, City of Los Angeles""}","2015-09-23","2015-09-23  13:00","Splunk Cloud as a SIEM for Cybersecurity Collaboration",Cloud,"Cloud ","Breakout Session"
84,10,"This presentation discusses Splunk's various .conf configuration files and Splunk Professional Services best practices for building and scaling out an environment. The presentation covers proper use and tips/tricks with the use of the deployment server, master node, and the search head cluster deployer. Emphasis is placed on the importance of proper configuration file management to ensure ease of management and quicker time to value.","2015-09-23  13:45",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Best Practices""}","{""name"":""Aaron Kornhauser"",""title"":""Sr Professional Services Consultant, Splunk""}","2015-09-23","2015-09-23  13:00","Conquering Config Confusion and Curating User Content in Search Head Clustering",Deploying,"Deploying ","Breakout Session"
81,10,"The growth of hybrid frameworks for mobile applications is impressive. The performance of HTML and JavaScript on mobile devices is getting better and better, the development is easier and cheaper and we have come to the point that's really hard to tell a native developed application from a hybrid one. But how can someone gain Operational Intelligence on the hybrid apps, since there are no available SDKs for that? Splunk MINT introduced the hybrid solution that allows developers to use the native methods of the SDKs though JavaScript. In this session, we will present and guide developers on how they can get started with Splunk MINT. We will provide special focus on using Splunk MINT to manage hybrid mobile apps.","2015-09-23  13:45",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Best Practices""}
{""name"":""Getting Data In""}","{""name"":""Kostas Polychronis"",""title"":""Head of Mobile, Splunk MINT, Splunk""}","2015-09-23","2015-09-23  13:00","Collecting Data from Hybrid Applications","Application Delivery","Applications Management ","Breakout Session"
P1,,,"2015-09-23  12:45",,"122-123--124 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-23","2015-09-23  12:00",,,,
79,9,"Have you ever said ""I wish I could do _____ in Splunk?"" When I ask myself that question, I exhaust every resource I have to get from ""I wish"" to ""I can."" In this talk, we'll cover a variety of unusual pro tips that you've always needed (or never knew you wanted until now).","2015-09-23  12:45","{""name"":""Public Sector""}
{""name"":""Technology""}","319 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Dan Aiello"",""title"":""Principal Cyber Security Engineer, Engineering and Technology Research Organization""}","2015-09-23","2015-09-23  12:00","Splunk Search Pro Tips","Splunk Classics","Splunk Classics ","Breakout Session"
87,9,"This session will be presented by Splunk technical product marketing and includes both slides and a live demo. It will teach:
-How and why the patterns of fraud, theft and abuse are often in machine data, log files, and structured datastores
-Very specific examples of the patterns of fraud across many industries, and also the data required to detect these patterns
-How you can harness all of this unstructured machine data and structured data to better detect, investigate and visualize fraud
-Detailed case studies on how organizations use Splunk software to defeat fraud, theft and abuse
It will also include a live demo of a prototype Splunk for Fraud Detection App that shows examples of how Splunk can be configured to help detect fraud.","2015-09-23  12:45",,"319 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Joseph Goldberg"",""title"":""Product Marketing, Security, Compliance, Fraud, Splunk""}
{""name"":""Young Cho"",""title"":""Solutions Architect, Splunk""}","2015-09-23","2015-09-23  12:00","How to Use Splunk to Detect and Defeat Fraud, Theft and Abuse","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
77,9,"Delivering actionable output from data science projects is not easy. The typical output of a scientific endeavor is the ""scientific paper,"" which is arguably about as far from actionable as you can get. Splunk output, on the other hand, is typically designed with the end action in mind. Our Splunk Development Team collaborates closely with our Security Data Science Team to take (sometimes esoteric) results from advanced security data science models and deliver actionable results using Splunk. The result is an accessible, normalized, iterable and repeatable delivery mechanism for complex and often esoteric data science model output. We'd like to share how we do it, so that you can do it too!","2015-09-23  12:45","{""name"":""Healthcare""}","304-305 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Data Science""}
{""name"":""Customer Success Story""}","{""name"":""Dave Dyer"",""title"":""Security Data Nerd, Kaiser Permanente""}
{""name"":""Tim Neyman"",""title"":""Cyber Security Consultant, Kaiser Permanente""}","2015-09-23","2015-09-23  12:00","Operationalizing Data Science Output Using Splunk","Big Data","Big Data ","Breakout Session"
76,9,"Winners of the Splunk Apptitude App Contest talk about and demo their submissions.","2015-09-23  12:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ",,"{""name"":""Monzy Merza"",""title"":""Minister of Defense, Splunk""}","2015-09-23","2015-09-23  12:00","How We Won $150K Through Our Splunk Apptitude!",Developing,"Developing ","Breakout Session"
86,9,"Windows logs are solid gold if you know what to Enable, Configure, Gather and Harvest. When hacked, they can tell you what you need to know to find and harvest the malware and what occurred. This talk walks through simple commodity malware seen in SPAM, drive-bys and a advanced nation state attacks, and what SIX Windows Event Codes and information in the logs allowed us to harvest their malware and understand what, where and when they were doing it.
Details of the attack from the logs and the queries used are covered and shared to allow you to catch a similar type of attack. This talk shows an advanced attack at its finest, but is designed to be Blue Team Defense in nature so you can learn from those that deal with malware and advanced attacks almost daily. What works and why will also be discussed. Handouts will be provided, as well as the Splunk queries used so you can start to use Splunk to monitor for such attacks.","2015-09-23  12:45",,"118 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}
{""name"":""Windows""}","{""name"":""Michael Gough"",""title"":""Founder, Malware Archaeology""}","2015-09-23","2015-09-23  12:00","Finding Advanced Attacks and Malware with 6 Windows EventIDs You Configure and Monitor","Security Compliance and Anti-fraud","Security and Compliance ","Breakout Session"
80,9,"Sure, SimpleXML is getting better and better and more interactive with each Splunk release, but JavaScript is the king of dynamic contents and interactivity! Wish a dashboard could display this and that when you hover there or click here? JavaScript to the rescue!","2015-09-23  12:45",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Visualization""}
{""name"":""Best Practices""}","{""name"":""Satoshi Kawasaki"",""title"":""Professional Services Consultant, Splunk""}","2015-09-23","2015-09-23  12:00","Enhancing Dashboards with JavaScript!","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
78,9,"Use Splunk alerts to trigger custom actions or integrate with pre-packaged, third-party solutions such as trouble ticketing systems, messaging services, or security solutions.
Integrate Splunk software into your enterprise ecosystem with custom alert actions to automate workflows and improve efficiency. Learn how an administrator would discover, install and use alert actions in their Splunk environment. Beyond using custom alert actions, we will demonstrate how to build an alert action from scratch using the new framework.","2015-09-23  12:45",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Best Practices""}","{""name"":""Siegfried Puchbauer"",""title"":""Senior Software Engineer, Splunk""}
{""name"":""Nicholas Filippi"",""title"":""Principal Product Manager, Splunk""}","2015-09-23","2015-09-23  12:00","Creating and Using Custom Alert Actions","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
,,,"2015-09-23  12:45",,"Community Theater Marquee Ballroom ",,,,,,"2015-09-23","2015-09-23  12:00",,,"Using Splunk/Search Language ",
,,,"2015-09-23  12:45",,"Community Theater Marquee Ballroom ",,,,,,"2015-09-23","2015-09-23  12:00",,,"Developing ",
66,8,"Processes like trade settlement in financial institutions, new service activation in telcos, claims processing in healthcare etc., are examples of complex business processes that span heterogeneous systems within an organization. With increasing complexity of IT landscapes, gaining end-to-end visibility into these critical business process is important for increased efficiency and for delivering superior customer service. Learn how leading organizations across industries are leveraging Splunk software to gain valuable insights by monitoring end-to-end complex business processes.","2015-09-23  12:00",,"113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Business Manager""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Business Analytics""}","{""name"":""Manish Jiandani"",""title"":""Director Solutions Marketing, Splunk""}","2015-09-23","2015-09-23  11:15","Splunk for Business Process Analytics","Business Analytics","Business Analytics ","Breakout Session"
73,8,"Geospatial or location-based data has found widespread use in many organizations for mobile phone users, business transactions and industrial operations. In this talk, we will reveal a new visualization type that allows you to see your geospatial data on a map, explore patterns, and analyze your data visually. You will learn when to use it to make the most of your data and we?ll show you how to create visualizations in a matter of just a few minutes. 
Learn where your customers spend the most, where security threats come from, and find surprising patterns in many more areas, through the power of geographic representations.","2015-09-23  12:00",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Visualization""}","{""name"":""Michael Porath"",""title"":""Product Manager, Splunk""}
{""name"":""Geoffrey Hendrey"",""title"":""Architect, Splunk""}","2015-09-23","2015-09-23  11:15","Paint By Number: The New Geo Visualization in Splunk","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
71,8,"An approachable talk on using Splunk's SDK's to build modular inputs that extend Splunk's capabilities. Why modular inputs over scripted inputs? What does the base code look like to build a modular input? How do I test my modular input? Do I need a setup screen? We will cover all these topics by deconstructing an app I wrote with a modular input to pull events from the Zenoss JSON API.","2015-09-23  12:00",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}","Good for All Skill Levels ",,"{""name"":""Scott Haskell"",""title"":""Client Architect, Splunk""}","2015-09-23","2015-09-23  11:15","Modular Inputs - If You Build It, They Will Come",Developing,"Developing ","Breakout Session"
65,7,"What happens to your complex applications after they're released into the wild? Do you have questions like these with no replies: Oh gosh what has happened to it after go-live? Are the users of the application even happy with it, or at least using it? Did they know about that awesome feature that makes life so easy? Is it performing ok?
As part of the application lifecycle process at Ernst and Young, we deliver solutions for our auditors to use in the field and also for our IT team to manage these solutions. We have used Splunk to quickly get answers on critical questions through DEV/TEST/RELEASE cycles.
From IT execs to Dev to Ops, everyone has what they need to easily understand the state of the product and keep it operational, as well as key feature usage. I invite you to come have a look at what we have done, so we can all keep making lives better through technology.","2015-09-23  12:00","{""name"":""Technology""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Rob Schlotman"",""title"":""Head of Design and Engineering, Global Consulting Organization""}","2015-09-23","2015-09-23  11:15","Managing Complex, Custom-Built Applications With Splunk","Application Delivery","Applications Management ","Breakout Session"
68,8,"This session will cover how indexer clustering works, various configurations, different problems as the cluster scales up, and tips and tricks to get improved performance.

","2015-09-23  12:00",,"115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Intermediate ",,"{""name"":""Da Xu"",""title"":""Senior Software Engineer, Splunk""}","2015-09-23","2015-09-23  11:15","Indexer Clustering Best Practices, Tips and Tricks",Deploying,"Deploying ","Breakout Session"
74,,,"2015-09-23  12:00",,"319 (Level 3) ",,,"Intermediate ",,,"2015-09-23","2015-09-23  11:15",,,"Security,Compliance and Fraud ",
CT5,8,"So you already know what Splunk can do, but you want to show others around you?  When you show them, they want it also, but they have to justify the cost benefit analysis to their management.  What are the steps to be successful in a humongous corporate enterprise environment?  We will walk through how we have been able to get our users to love Splunk and in turn show their management how it is making them more productive.","2015-09-23  12:00","{""name"":""Healthcare""}","Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Aaron Blythe"",""title"":""Knowledge Architect, Cerner Corporation""}","2015-09-23","2015-09-23  11:15","Guerrilla Marketing - How to Sell Splunk Internally to Your Enterprise",Adopting,"Adopting ","Breakout Session"
72,8,"The emergent containerization of services with technologies like Docker and Mesos in the cloud is enabling enterprises to deploy services in the cloud faster with less resources and at higher scales than ever before. The emergent streaming platform is allowing services to log to Kafka at high throughputs, with low latency, near real time speeds. How do you Splunk the logs of all those containers? In this session you will see how HomeAway is using Mesos, Kafka, Avro SchemaRegistry and Storm to allow containers to log to Splunk to gain near real-time insight into machine intelligence in the cloud.
Come and find out how HomeAway is leveraging Splunk, the Cloud and the emergent Streaming Platform to gain insights on a rapidly growing business while having fun doing it and still getting home in time for dinner.","2015-09-23  12:00","{""name"":""Online Services""}
{""name"":""Travel and Transportation""}","120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Rene Parra"",""title"":""Principal Architect, HomeAway Inc.""}","2015-09-23","2015-09-23  11:15","Emergent Big Data Streaming Platform in the Cloud","Big Data","Big Data ","Breakout Session"
67,8,"Orion builds beautiful, wearable accessories that utilize Splunk's distributed, web-scale platform to provide near real-time group communications capabilities. We will show how Orion utilizes the power and flexibility of Splunk Cloud to dive deep into our platform to understand critical performance issues as well as fly high in order to extract an important global understanding of our internet-connected accessories. You will learn how Orion leverages the cloud, wearables, and IoT to provide an amazing and seamless communications experience.","2015-09-23  12:00","{""name"":""Communications""}
{""name"":""Technology""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}","{""name"":""Dan Phung"",""title"":""Software Engineer, Orion""}
{""name"":""Rajiv Battula"",""title"":""Software Engineer, Splunk""}","2015-09-23","2015-09-23  11:15","Cloud, Wearables, and IoT! How Orion Leverages Splunk Cloud to Ensure Performance and Gain Analytics from Internet-connected Accessories",Cloud,"Cloud ","Breakout Session"
9,8,"The next version of Splunk App for Enterprise Security has unleashed new capabilities for Cyber detectives and threat hunters. Learn how to use Extreme Search and how to write correlation searches.","2015-09-23  12:00",,"118 (Level 1) ","{""name"":""Splunk App for Enterprise Security""}","{""name"":""Administrator""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Jack Coates"",""title"":""Director, Product Management, Splunk""}
{""name"":""Macy Cronkrite"",""title"":""Professional Services, Splunk""}","2015-09-23","2015-09-23  11:15","Splunk App for Enterprise Security: Extreeeeeme Correlation Searches","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
69,7,"The collaborative security model is a framework that extends Splunk's existing monitoring solution by an open and expandable abstraction layer for security commands. The aim is to build a true ecosystem, which allows all security solution providers to participate by expanding the framework with their own application. The framework establishes a standardized two-way communication channel, that enables security components to be managed centrally. Another advantage is the abstraction layer. This ensures security providers can easily be replaced at any time with a new, more suitable product.

In our joint efforts for phase 1, we brought a number of providers onboard, such as Intel, Fortinet, Palo Alto Networks and EMC. The goal is to build a prototype to further enable manufacturers to participate in the ecosystem.","2015-09-23  12:00","{""name"":""Communications""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}
{""name"":""CISO""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Christof Jungo"",""title"":""Head of Security Architecture, Swisscom Switzerland ltd.""}
{""name"":""Haiyan Song"",""title"":""SVP, Security Markets, Splunk""}","2015-09-23","2015-09-23  11:15","Collaborative Security Model","Security Compliance and Anti-fraud","Security and Compliance ","Breakout Session"
70,8,"Penn State Hershey is building out its cyber Sscurity capabilities, with Splunk App for Enterprise Security as a key component of our strategy. In this session, the speaker provides his experiences over the past year in building out the program, implementing several key cyber technologies, and on how Splunk was leveraged as a force multiplier.","2015-09-23  12:00","{""name"":""Healthcare""}
{""name"":""Higher Education""}","101-102 Panel Room ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Jeff Campbell"",""title"":""Cyber Security, Penn State Hershey Medical Center""}","2015-09-23","2015-09-23  11:15","Building a Cyber Security Program with Splunk App for Enterprise Security","Security Compliance and Anti-fraud","Using Splunk/Search Language ","Breakout Session"
60,7,"Splunk is a powerful data-inspection tool with a number of built-in visualization options. But the Splunk platform also includes many ways for users to extend and customize its visualization capabilities. Using Splunk's Web Framework and some knowledge of JavaScript, developers can include third-party charting libraries and visualizations in Splunk apps and dashboards or create custom experiences for seeing and exploring their data.
This session is an end-to-end overview of how to go from raw Splunk data to custom visualization with JavaScript. It covers the basics of how Splunk core visualizations work, using the Splunk Web Framework to easily get raw data from Splunk, managing raw data for use in visualization, using visualization techniques, using third-party graphics libraries, and creating custom experiences from Splunk data.
Beginner-level understanding of JavaScript and web development will help attendees follow along. Intermediate and advanced developers will feel right at home.","2015-09-23  10:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Visualization""}
{""name"":""Best Practices""}","{""name"":""Marshall Agnew"",""title"":""Software Developer, Splunk""}","2015-09-23","2015-09-23  10:00","Visualizing Data From the Ground Up: Raw Data to Interactive Graphics With Splunk",Developing,"Developing ","Breakout Session"
52,7,"A good user experience is key for any growing and successful company, but user experience involves far more than the arrangement of pixels on a screen. Everything you do impacts user experience, from ensuring high-performance code to a well-tuned server. All these different layers can add complexity and trip you up when an issue arises. In this session, we'll share how the Policy Administration System (PAS) application team at CSAA Insurance Group uses Splunk to gain better visibility from the end user's browser all the way to the CPU on the database. 
By using Splunk software to merge APM tools like Dynatrace, application logs, and traditional IT ops monitoring tools, the PAS App was able to focus on how technical metrics translated to customer satisfaction. Feeding production performance metrics back into the development and testing process along with improved capacity planning, changes the focus from infrastructure growth back to business growth.","2015-09-23  10:45","{""name"":""Financial Services""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Business Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Diviyesh Patel"",""title"":""DevOps and Optimization Manager, CSAA Insurance Group""}
{""name"":""Doug Erkkila"",""title"":""Capacity Management Analyst, CSAA Insurance Group""}","2015-09-23","2015-09-23  10:00","Splunking the User Experience: Going Beyond Application Logs","Business Analytics","Business Analytics ","Breakout Session"
58,7,"Today, cheap commodity servers contain lots of cores. At customer sites, we often see more than 24 cores on indexer machines.
Each Splunkd instance contains a series of pipelines (Pipelineset) starting from input pipelines that feed data to Splunk, parse data and finally, index or forward data. Traditionally, this series of pipelines used to limit the number of cores splunkd could use on a machine. And our suggestions so far have been to install additional Splunk instances to increase resource utilization. However, this approach is deficient in many ways.
In this presentation, we'll talk about the multiple PipelineSet features of splunkd and how they address the above constraint.
The basic goal of this subject is to have parallel independent instances of Pipelinesets. The number of these parallel PipelineSets can be configured based on customer environments, depending on the number of cores available and other applications running on the machine.","2015-09-23  10:45",,"120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Advanced ",,"{""name"":""Jag Kerai"",""title"":""Director of Engineering, Splunk""}
{""name"":""Abhinav Nekkanti"",""title"":""Software Engineer, Splunk""}","2015-09-23","2015-09-23  10:00","Splunkd with Multiple Pipelinesets","Splunk Classics","Splunk Classics ","Breakout Session"
61,7,"The flexibility of search language, along with the distributed indexing, are critical parts of Splunk's unique advantages. To advance to the next level, one expects frameworks to be more intelligent, able to unburden people from the deluge of data and to use it to gain insights. To provide such intelligence, machine/statistical learning provides an arsenal of tools. To handle the amount of data that?s continualy increasing, scalable distributed computing is a basic requirement. Spark is one of the most actively and well-architected distributed computation frameworks that has SQL support, with scalable machine learning and graph processing libraries built on top of this architecture.","2015-09-23  10:45",,"304-305 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""IT Operations""}","{""name"":""Liu-yuan Lai"",""title"":""Engineer, Splunk""}","2015-09-23","2015-09-23  10:00","Splunk Distributed Processing With Spark","Big Data","Big Data ","Breakout Session"
53,7,"Aurizon is the largest rail freight operator in Australia, transporting more than 250 million tons of Australian commodities each year. Aurizon also owns and operates the world?s largest coal rail network. Join us in this session to hear how Aurizon expanded its on-premises Splunk Enterprise deployment with Splunk Cloud by leveraging Splunk Cloud's hybrid search capabilities. Also learn how Aurizon overcame internal deployment obstacles to successfully leverage Splunk Cloud. ","2015-09-23  10:45","{""name"":""Travel and Transportation""}","113 (Level 1) ","{""name"":""Splunk Cloud""}
{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}","Good for All Skill Levels ","{""name"":""Cloud Solutions""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Sebnem Kurklu"",""title"":""Information Security Manager, Aurizon""}
{""name"":""Simon O'Brien"",""title"":""Solutions Architect, Splunk""}","2015-09-23","2015-09-23  10:00","Splunk Cloud Hybrid Search: How Aurizon Expanded Its Existing Splunk Enterprise Deployment With Splunk Cloud",Cloud,"Cloud ","Breakout Session"
54,7,"Deployment Server is the Splunk tool for configuration distribution. In this session, we discuss some ways to scale Splunk deployment server. You will also learn about the new improvements being made for this feature in the next release. 
We'll also do a deep dive into deployment topologies - the how, where and why. ","2015-09-23  10:45",,"119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}","Intermediate ",,"{""name"":""Jag Kerai"",""title"":""Director of Engineering, Splunk""}
{""name"":""Pratiksha Shah"",""title"":""Software Engineer, Splunk""}","2015-09-23","2015-09-23  10:00","Scaling Deployment Server",Deploying,"Deploying ","Breakout Session"
59,7,"How can system incidents be stopped before they happen? Within healthcare's revenue cycle, data must be analyzed quickly and effectively in order to prevent unwanted events and produce predictable outcomes. Learn how Cerner Corporation is using Splunk software to analyze data from multiple revenue cycle systems and partners to produce alerts, reports and dashboards that provide actionable insights in a real-time fashion. Learn how various system logs, Splunk DB Connect and other technologies such as IBM's WAS are utilized and leveraged by Splunk to produce a optimal operating environment and ongoing system intelligence.","2015-09-23  10:45","{""name"":""Healthcare""}","121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Chris Hogan"",""title"":""Sr Solution Architect, Cerner Corporation""}
{""name"":""Tom Twait"",""title"":""Solution Architect, Cerner Corporation""}","2015-09-23","2015-09-23  10:00","Predict, Alert, Manage and Optimize an Ecosystem With Splunk","Business Analytics","Business Analytics ","Breakout Session"
51,8,"A Splunk Technical Champion is a leader who works to maximize the value of their company's Splunk investment by promoting rapid and widespread adoption of Splunk. Learn how to become a strong champion by bridging business units and silos to realize the immense value of machine data and analytics. Get inspired with actionable, tried-and-true strategies from peers who have made the shift. The difference between Splunk being used as a point tool versus Splunk being leveraged as a machine data platform delivering deep business and operational insights, is you.","2015-09-23  10:45",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Advanced ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Sean Delaney"",""title"":""Client Architect, Splunk""}
{""name"":""Vi Ly"",""title"":""SE Specialist Manager, Splunk""}","2015-09-23","2015-09-23  10:00","Lead the Charge as a Strong Splunk Technical Champion",Adopting,"Adopting ","Breakout Session"
62,7,"Oh great! Your developers have come to you and said they want to send events from their apps to Splunk AND they don?t want to use a forwarder. What do you tell them? 
In the next version of Splunk, we?re introducing an endpoint that developers can use to send JSON application events into Splunk directly: the HTTP Event Collector. It works out-of-the-box, does not require a forwarder, and is very easy to manage and configure. It provides a new lightweight token-based authentication mechanism, so you can easily secure it. Best of all, it is designed for high scale-out and availability.
In this session, we?ll take a look at the new collector, why your developers want to use it, how to configure it, and everything you need to know about deploying and maintaining it.","2015-09-23  10:45","{""name"":""Technology""}","319 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Log Management""}
{""name"":""Application Delivery""}
{""name"":""IT Operations""}
{""name"":""Best Practices""}","{""name"":""Glenn Block"",""title"":""Senior Product Manager, Splunk""}","2015-09-23","2015-09-23  10:00","The HTTP Event Collector, a New Way for Developers to Send Events to Splunk","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
75,7,"Ever wanted to add maps to your dashboards? This session will cover the fundamentals of using maps in Splunk. From adding location data to your events, plotting them on maps and styling the maps, we will cover it all. This session will teach you the fundamentals of why and when you would want to use maps, the tools you need and examples of how to do this.","2015-09-23  10:45",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IoT and Industrial Data""}
{""name"":""Log Management""}
{""name"":""Visualization""}
{""name"":""Best Practices""}","{""name"":""Robb Bittner"",""title"":""Sr. Product Manager, Splunk""}
{""name"":""Michael Porath"",""title"":""Product Manager, Splunk""}","2015-09-23","2015-09-23  10:00","Getting Started with Maps","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
64,7,"If a KPI degrades and no one is around to see it, does it make a noise?
With Splunk alerting integration to your NOC, it will!
Get your techs paged and engaged by leveraging Splunk to notify your 24x7 surveillance teams of network or service degradations.  
See how Telus Network Operations is using Splunk Alerts, KVStore, REST API and SNMP to identify network/service degradations early to ensure our clients don't.","2015-09-23  10:45","{""name"":""Communications""}","320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""IT Operations""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Matthew Modestino"",""title"":""Network Specialist, Telus""}","2015-09-23","2015-09-23  10:00","Keep Your Eyes on the KPIs! Enhancing Reliability with Splunk Alarming into your NOC","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
56,7,"Splunk offers Splunk MINT, which enables you to deliver better performing and more reliable mobile apps. In order to acquire mobile intelligence, Splunk MINT requires action on both the Splunk Admin and the mobile app developer.
This session outlines how to get up and running with Splunk MINT. We will first walk through the steps that mobile developers need to perform, then go through the steps that Splunk Admins need to take. We'll also show you some cool capabilities of Splunk MINT along the way.","2015-09-23  10:45",,"115-116 (Level 1) ","{""name"":""Splunk MINT""}
{""name"":""Splunk Enterprise""}","{""name"":""Developer""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""IT Operations""}","{""name"":""Panos Papadopoulos"",""title"":""Director of Product Management, Splunk""}","2015-09-23","2015-09-23  10:00","Getting Started with Splunk MINT","Mobile Intelligence","Mobile Intelligence ","Breakout Session"
CT4,7,"Customers of a certain bank started reporting cases of wire transfers not being delivered. Clients threatened with lawsuits. The bank lost its reputation. The Anti-fraud team is helpless. The Security Analysts find some suspicious event sequences in custom application and web servers logs, which indicate, that someone had snatched clients passwords.
An attempt to solve the problem of automated detection of fraud with old school Unix tools as egrep, sed, awk, cron, leads to a quick-and-dirty, temporary, partial solution, nobody is fully satisfied with. The Anti-Fraud team still needs a solid and flexible tool, providing support for fraud detection.
During my speech I would like to present main Fraud Detection tool features which we built for one of our customers. I will demonstrate how we utilized Splunk to quickly build such a tool.","2015-09-23  10:45",,"Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Tomasz Dziedzic"",""title"":""Senior Service Architect, Linux Polska""}","2015-09-23","2015-09-23  10:00","From Zero to Pretty Robust Fraud Detection Tool","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
57,7,"Cyber-attacks and insider threats are increasingly difficult to detect. The fundamental challenge for today's organizations is in the sheer scale of event data and the substantially longer timelines over which advanced attacks occur. These challenges require big data scale and smart threat detection software that watches for threat patterns over weeks, months, or years in order to catch stealthy and polymorphic threats: advanced persistent threats (APTs) or low, slow, and hidden attacks such as insiders. Learn how Splunk User Behavioral Analytics (UBA) leverages data science and machine learning to crunch through billions of events and stitch hundreds of anomalies into actionable threats.","2015-09-23  10:45","{""name"":""Public Sector""}
{""name"":""Technology""}","119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Anarag Gurtu"",""title"":""Product Marketing, Splunk""}","2015-09-23","2015-09-23  10:00","Leveraging Data Science and Machine Learning to Combat Cyber-attacks and Insider Threats","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
39,6,"A technical review on how to measure and report on the overall health and utilization of your Splunk installation.
We'll cover the building and implementing of KPIs and SLAs that can be measured and reported on to management. We do this through the collection of IO and compute metrics, summarized license data and introspection index data, and allow fir differences based on bare-metal deployments/virtualization or cloud implementations of Splunk.
The session is a practical foray into troubleshooting and tools that can help determine what is going on under the hood of your indexers, forwarders and search heads. Examples include how to utilize btool commands, File::Tail status, and REST commands, as well as how to implement a custom command when those don't quite fit the bill.
Lastly, we'll look at basic capacity management and what factors play into how your Splunk installation is expected to grow over time.","2015-09-22  17:45","{""name"":""Communications""}","111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}","Advanced ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Joe Cramasta"",""title"":""Senior Engineer, Comcast""}
{""name"":""Kate Lawrence-Gupta"",""title"":""Principal Engineer, Comcast""}","2015-09-22","2015-09-22  17:00","To Xfinity and Beyond: Mission-Critical Metrics and Tips for Managing Any Size Splunk Installation",Adopting,"Adopting ","Breakout Session"
42,6,"Installing Splunk Universal Forwarders is simple enough, but installing it effectively takes more work. Manual installation can be time consuming, and error prone if there is not some structure around the installation. Typos can render an installation of the Splunk UF useless, even detrimental to your environment.
In this session, we'll share best practices from our Splunk instance. We use a set of scripts to enable the installation of the UF on Linux, AIX and Windows to be able to be done by non-Splunk-savvy administrators so that there are no mistakes or errors in the install or configuration. This also requires effective use of the Deployment Server. In this manner the UF can be selectively installed as needed by the owners of the host services.
As a result of the scripted installation, errors in the installation are eliminated and only minimal work needs to be done by a Splunk administrator, making better use of the administrator's time and talents.","2015-09-22  17:45","{""name"":""Nonprofit""}","115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Customer Success Story""}","{""name"":""Cary Petterborg"",""title"":""Senior Monitoring Engineer, LDS Church""}","2015-09-22","2015-09-22  17:00","Simplified Forwarder Deployment and Deployment Server Techniques",Deploying,"Deploying ","Breakout Session"
44,6,"It is an unquestioned fact that consumers rely on mobile more and more each day. Transactions are moving from PCs and laptops to mobile devices and tablets. Splunk is able to collect and process petabytes of data that are produced by your servers and websites. But what about the data created from mobile? Splunk MINT (Mobile Intelligence) is the answer. 
With Splunk MINT, you automatically get insights, analytics, performance data and crash data but you can also gather more data to track user analytics and behavior, events and transactions. For all those with the power of Splunk Enterprise!","2015-09-22  17:45",,"118 (Level 1) ","{""name"":""Splunk MINT""}
{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Administrator""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}","{""name"":""Kostas Polychronis"",""title"":""Head of Mobile, Splunk MINT, Splunk""}","2015-09-22","2015-09-22  17:00","Supercharge Your Mobile App Delivery with Splunk MINT","Mobile Intelligence","Mobile Intelligence ","Breakout Session"
49,6,"Introduced in Splunk 6.2, the Distributed Management Console helps Splunk Admins deal with the monitoring and health of their Splunk deployment. In the next version of Splunk, we built views for Splunk Index and Volume Usage, Forwarder Monitoring, Search Head Cluster Monitoring, Index Cluster Monitoring, and tools for visualizing your Splunk Topology.","2015-09-22  17:45",,"318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}","Intermediate ","{""name"":""Best Practices""}","{""name"":""Patrick Ogdin"",""title"":""Product Manager, Splunk""}
{""name"":""Octavio Di Sciullo"",""title"":""Supportability Engineering Liaison, Splunk""}","2015-09-22","2015-09-22  17:00","Splunk Distributed Management Console: New Views for the DMC in the Next Version of Splunk","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
CT3,6,"Ask yourself the following:
What if you could unleash your potential with like-minded people in a safe environment?
What if you could create sustainable enthusiasm, energy and inspiration?
What if you could make a real contribution that rewards you with both growth and influence?
What if you could have insights into the big picture and what actually works in the real world?

Now that we have your attention: 
What if we showed you how easy it is to set up a user group?
What if we showed you how to successfully manage a user group and everything involved?
What if we showed you how to join forces with user groups around the world to gain even more insight and knowledge?
What if we showed you what outstanding looks like?

When it comes to managing user groups and uniting the community, Tony rocks! When it comes to unleashing potential and creating energy and emotion, Aleem rolls. So if you want rock 'n' roll while being entertained, you are in for a treat.","2015-09-22  17:45","{""name"":""Technology""}
{""name"":""Healthcare""}","Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Aleem Cummins"",""title"":""CTO, Computacenter""}
{""name"":""Tony Reinke"",""title"":""Lead Systems Enginner, National Research Corporation""}","2015-09-22","2015-09-22  17:00","Splunk User Groups: More Than Pints and Pizza","Community Theatre",,"Breakout Session"
50,6,"Gain a comprehensive understanding of search efficiency optimization techniques at the search line, along with which techniques to avoid. Evaluate search time efficiency and performance for many common use cases. Learn about summary indexes, search accelerations, lookup tables, saved searches and jobs, and pivot tables contribute to, and in some cases hide, search performance and efficiency.","2015-09-22  17:45",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}
{""name"":""Developer""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Log Management""}
{""name"":""Best Practices""}","{""name"":""Duncan Turnbull"",""title"":""Solutions Architect, Splunk""}
{""name"":""Julian Harty"",""title"":""Solutions Architect, Splunk""}","2015-09-22","2015-09-22  17:00","Search Efficiency Optimization","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
40,6,"Successfully running a large restaurant chain requires delivering accurate information about products to retail point-of-sale systems. This can be challenging when corporate and retail systems are disparate.
In this presentation, we will highlight an example that demonstrates how a large restaurant chain with over 3,500 locations uses Splunk software to find inconsistencies with product information and resolve them early in the business process?before they disrupt restaurant operations or cause a poor customer experience.
Additionally, the audience will learn how Splunk can be leveraged to acquire disparate sources of data to produce a consistent view of data for analysis and drive business processes.","2015-09-22  17:45","{""name"":""Retail""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Brandon Burk"",""title"":""Senior Director, Digital Technology, Sonic Corporation""}
{""name"":""Juan Gomez"",""title"":""Technical Architect, Sonic Corporation""}","2015-09-22","2015-09-22  17:00","Quick Service Data for Quick Service Restaurants","Business Analytics","Business Analytics ","Breakout Session"
41,6,"This session will be led by two former J.P. MorganChase leaders who brought Splunk with them to Orrstown Bank, an East Coast community bank with $1.2 billion in assets. They will show how Orrstown is using anomaly detection capabilities, running in Splunk Cloud, to tackle the growing volume of credit and debit card fraud. The presentation will also describe Orrstown Bank's use of Prelert?s Anomaly Detective product to identify fraudulent card transactions in a manner that?s cheaper and more flexible than traditional fraud detection solutions.","2015-09-22  17:45","{""name"":""Financial Services""}","114 (Level 1) ","{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Security Analyst""}
{""name"":""CIO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Cloud Solutions""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Andrew Linn"",""title"":""CISO, Orrstown Bank""}
{""name"":""Christopher Thompson"",""title"":""Senior Vice President and Chief Architect, Orrstown Bank""}","2015-09-22","2015-09-22  17:00","Orrstown Bank: Using Splunk Cloud and Anomaly Detection Capabilities To Fight a Billion Dollar Fraud Problem",Cloud,"Cloud ","Breakout Session"
47,6,"Your apps have a lot of log data just waiting to be freed, and your developers and DevOps folks are just waiting for the insight. Well, wait no longer! In the latest version of Splunk, we're breaking the chains and providing developers a new way to get app data efficiently into Splunk. It's HTTP-based, it's secure, it's highly available, and it can scale to whatever your needs. And, you don't need a forwarder! Come to this talk and see it in action.","2015-09-22  17:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Log Management""}
{""name"":""IT Operations""}","{""name"":""Glenn Block"",""title"":""Senior Product Manager, Splunk""}
{""name"":""Jian Lee"",""title"":""Senior Engineer, Splunk""}","2015-09-22","2015-09-22  17:00","Liberate Your Application Logging!",Developing,"Developing ","Breakout Session"
48,6,"This session will show how to marry the flexibility of EC2, Amazon EMR and S3 with the power of Hunk for Hadoop and NoSQL Data Stores to build distributed and scalable data exploration and analytics solutions on AWS. We will show how to go from raw data to dashboards and real insights within minutes--and with zero lines of code.","2015-09-22  17:45",,"304-305 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Hunk""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Cloud Solutions""}
{""name"":""Big Data""}
{""name"":""Best Practices""}","{""name"":""Dritan Bitincka"",""title"":""Principal Solutions Architect, Splunk""}","2015-09-22","2015-09-22  17:00","Hunk and Elastic MapReduce: Big Data Analytics on Amazon Web Services","Big Data","Big Data ","Breakout Session"
46,6,"Learn details of how splunkd receives data and how data is parsed, indexed and forwarded. Learn how to debug Splunk the way Splunk engineers debug.","2015-09-22  17:45",,"120 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Advanced ",,"{""name"":""Amrit Bath"",""title"":""Director of Input Operations, Splunk""}
{""name"":""Jag Kerai"",""title"":""Director of Engineering, Splunk""}","2015-09-22","2015-09-22  17:00","How splunkd Works","Splunk Classics","Advanced ","Breakout Session"
23,6,"Big Data -- we do that. Splunk Enterprise scales horizontally to ingest 100's of Terabytes of data each and every day, that you can easily search, run analytics, and report on historical data sets that are in multiple Petabytes. In this presentation, we will cover Splunk's distributed computing, horizontal scalability and fault tolerant architecture. Real world use cases and examples will be covered, so you will be inspired to jump into your own Data Lake.","2015-09-22  17:45",,"121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Deploying Splunk""}","{""name"":""Sean Delaney"",""title"":""Client Architect, Splunk""}
{""name"":""Mustafa Ahamed"",""title"":""Director, Product Management, Splunk""}","2015-09-22","2015-09-22  17:00","Go Big or Go Home",Deploying,"Deploying ","Breakout Session"
43,6,"Denver Water is located in one of the healthiest states in the U.S. Being healthy means different things for different people. If you have the time, you can read food labels to see what?s in your food, but what about when you turn on the tap? Our mission is to make sure customers receive clean, safe, great-tasting water every day.
Our drinking water is 100 percent surface water that comes from rivers, lakes, streams, reservoirs and springs fed by high-quality mountain snow runoff. We vigilantly safeguard our mountain water supplies, and we carefully treat the water before it reaches our customer's tap.
Part of ensuring water quality is making sure we have adequate monitoring of our water quality from our supplies through our treatment. To do this, we need analytics that leverage our existing SCADA/ICS system and our reservoir monitoring. In this presentation, we?ll show you how we made disparate sources available to different departments within Denver Water.
","2015-09-22  17:45","{""name"":""Energy and Utilities""}
{""name"":""Public Sector""}","117 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Advanced ","{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}","{""name"":""Andy Kuhn"",""title"":""Enterprise Architect, Denver Water""}","2015-09-22","2015-09-22  17:00","Deeper insights into Water Treatment Through Splunk","Internet of Things","Internet of Things ","Breakout Session"
151,6,"Yoox Group, the global leader in online luxury that recently acquired Richemont's Net-a-porter, adopted Splunk as integration fabric of their cybersecurity platform. Specifically Splunk provides real-time event correlation and analytics to allow intrusion detection and identification of recurrent malicious behavioural pattern. The violations of security policies are detected by an automatic alerting system and the incidents are visible into a comprehensive set of dashboards that enriches activity monitoring with deep investigation capabilities. Yoox is currently working to build an enterprise grade security intelligence platform with prediction and learning capabilities based on the current Splunk deployment; with this achievement they will make a step forward from a reactive approach to a more mature proactive one.","2015-09-22  17:45","{""name"":""Retail""}","122-123--124 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Security Analyst""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Gianluca Gaias"",""title"":""Head of Information Security, Yoox.com""}","2015-09-22","2015-09-22  17:00","Building an Enterprise-grade Security Intelligence Platform at Yoox.com","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
45,6,"Whether it's through your internal security team or via a letter from the FBI, being notified that your company has been compromised is in no way a good thing. These events, however inevitable they may be, send chills down your spine and put you directly into disaster recovery mode. The reaction is often multiplied by the sheer scope of the compromise once you realize that the breach encompasses a multitude of systems, and not just the one or two you were initially alerted to. Thousands of endpoints and it's now your job to develop an effective remediation strategy that not only removes the current threat from the environment but also reduces the chances of the attacker re-compromising the environment post remediation. This discussion will show how Splunk App for Enterprise Security can be used to scope and manage a breach in a structured and organized manner. Making an already stressful situation feel a little less daunting.","2015-09-22  17:45",,"319 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk App for Enterprise Security""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Brian Luger"",""title"":""Software Engineer, Security, Splunk""}","2015-09-22","2015-09-22  17:00","Breach Management in Splunk App for Enterprise Security","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
32,5,"This talk is a must for C-level audiences and security practitioners alike. What if a well-resourced, advanced and malicious organization chose to use Splunk? What if your sophisticated adversary had a single pane of glass for exploitation, monitoring, command and control, billing, and Operational Intelligence? How would you compete with an already advanced adversary who is now using Splunk for Operational Intelligence? Leave your SIEM at home, this is going to hurt! 
This is an offensive talk. We will demonstrate the Crimeware Operation App for Splunk. To date, Splunk is thought of as a defensive tool. In this talk, we will demonstrate how our app is used for exploiting, managing and monetizing compromised business targets. We will show how a sophisticated attacker organization runs their business with Splunk at the center of their operations: keeping track of compromised systems, identifying new targets, discerning which targets are most lucrative and analytics for their customers?all with one motive: keeping control of your assets while making money! 
Attendee takeaway: This talk will highlight how Splunk software can be used by a malicious organization as a single pane of glass for configuration management, IT operations and business analytics. And if attendees are not using Splunk, attendees will learn that they don?t stand a chance of competing with a well-resourced adversary who is now using Splunk! 

","2015-09-22  17:00",,"122-123--124 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""CISO""}
{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Monzy Merza"",""title"":""Minister of Defense, Splunk""}","2015-09-22","2015-09-22  16:15","Using Splunk for Cyber Crime: How Would You Compete When Your Sophisticated Adversary Levels Up to World-Class Operational Intelligence?","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
35,5,"In this Hunk session, we will examine the knobs to improve Hunk performance. We will show the best way to improve from a million events in 40 minutes to well over 100s of million events within 4 minutes. We will examine real world deployments and see what Hunk best practices work and what we should avoid. We'll also discuss the common challenges with Hunk Deployments and how to troubleshoot and fix them. ","2015-09-22  17:00",,"304-305 (Level 3) ","{""name"":""Hunk""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Advanced ","{""name"":""Big Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Best Practices""}","{""name"":""Raanan Dagan"",""title"":""Sr Sales Engineer, Hadoop specialist, Splunk""}
{""name"":""Praveen Burgu"",""title"":""Senior Software Engineer, Splunk Inc""}","2015-09-22","2015-09-22  16:15","Splunk Hunk - Performance, Best Practices, Troubleshooting","Big Data","Big Data ","Breakout Session"
28,5,"Search Head Clustering is Splunk's horizontal scaling solution for searches. As enterprises onboard more users onto Splunk deployments and the need for dashboards and alerts goes up, and search heads need to be scaled out horizontally to manage the search load.
Search Head Clustering solves this by providing highly available search heads. Administrators can group a set of machines into search head clusters and add and remove nodes dynamically as and when their requirements change.
The search heads are behind sticky load balancers which distribute the user sessions across the search head cluster members. The scheduled searches and alerts are automatically load balanced across the cluster. Configuration changes done on one search head are replicated across the members, giving an identical look and feel.
Searches are universally available throughout the cluster which gives a uniform view across the cluster. These topics and more will be covered in this session.","2015-09-22  17:00",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Advanced ",,"{""name"":""Manu Jose"",""title"":""Senior Engineer, Splunk""}
{""name"":""Eric Woo"",""title"":""Senior Engineer, Splunk""}","2015-09-22","2015-09-22  16:15","Search Head Clustering",Deploying,"Deploying ","Breakout Session"
29,,,"2015-09-22  17:00",,"117 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-22","2015-09-22  16:15",,,"IT Operations ",
31,,,"2015-09-22  17:00",,"120 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-22","2015-09-22  16:15",,,"Adopting ",
27,5,"Building applications in the cloud brings many promises of increased speed and agility at a lower cost. But these benefits are only realized if your cloud infrastructure is secure and well managed. Learn how FINRA leverages Splunk Cloud to manage its AWS environment through security and compliance, monitor project costs and optimize its compute and storage resources.

In this session, we discuss the AWS shared responsibility model and a new developer responsibility paradigm that cloud development inherently brings. We will show how FINRA has taken advantage of Splunk?s collection methods supplemented with its own custom collection methods so that it can use Splunk Cloud to address these new cloud-based responsibilities.","2015-09-22  17:00","{""name"":""Financial Services""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Application Delivery""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Gary Mikula"",""title"":""Senior Director, Information Security Engineering, FINRA (Financial Industry Regulatory Authority)""}","2015-09-22","2015-09-22  16:15","Leveraging Splunk to Manage Your AWS Environment",Cloud,"Cloud ","Breakout Session"
CT2,5,"The Splunk Add-on for JIRA brings the results of JQL searches into Splunk, allowing you to correlate JIRA activity with the rest of your events, and produce reports and visualizations far beyond what JIRA is capable of out-of-the-box.
In addition to JQL searches, the Add-on for JIRA can query other JIRA REST API endpoints, such as Agile/Greenhopper (sprints) and the user activity stream.
This talk introduces the Add-on for JIRA, demonstrates its features and shares some Splunk use cases that we're addressing.","2015-09-22  17:00",,"Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Application Delivery""}","{""name"":""Russell Uman"",""title"":""Senior Web Engineer, Splunk""}","2015-09-22","2015-09-22  16:15","How Splunk Uses the Splunk Add-on for JIRA","Community Theatre",,"Breakout Session"
36,5,"Today's commodity servers contain lots of cores. In customer sites, we often see more than 24 cores on indexer machines. How can we ensure that the Splunk indexer is making the most of the resources available on these servers? 
The next version of Splunk software introduces two features to improve its resource utilization and performance gains: 
1) Parallel Ingestion PipelineSets: Spawning parallel PipelineSets increases the rate at which Splunk can read, parse and index data
2) Search parallelization: Parallelizing the search pipelines and the summary indexing provides significant performance gains for reporting searches.","2015-09-22  17:00","{""name"":""Technology""}","318 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}","Advanced ",,"{""name"":""Sourav Pal"",""title"":""Engineer, Splunk""}
{""name"":""Abhinav Nekkanti"",""title"":""Software Engineer, Splunk Inc""}","2015-09-22","2015-09-22  16:15","Harnessing Performance and Scalability in the Next Version of Splunk","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
16,5,"Vertu is a British manufacturer of luxury, handmade mobile phones. This in depth technical session will give a live demonstration of deploying a Splunk cluster to the Cloud using the leading edge DevOps tool: Ansible.  Once up and running we'll use the new cluster to show how we analyse data from our Android mobile phones during the productization phase.  Find out how we track phone crashes to work out the mean time between failures (MTBF) figure before we launch a phone. ","2015-09-22  17:00","{""name"":""Retail""}
{""name"":""Manufacturing""}","118 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""IT Operations""}
{""name"":""Customer Success Story""}","{""name"":""Rob Charlton"",""title"":""Cloud DevOps Architect, Vertu Corporation Ltd""}","2015-09-22","2015-09-22  16:15","Deploying a Splunk Cluster to the Cloud with DevOps Tools and Using Splunk to Improve Reliability in a Fleet of Mobile Devices","Application Delivery","Applications Management ","Breakout Session"
25,5,"Adoption of new tools in an organization are not always straightforward. Changing requirements, customer growth, end-user ability can impact even the best-laid plans.
This presentation will walk through the driving factors and challenges of crossing the multi-TB license boundary, going on a Splunk ""diet"" to reduce growing licensing costs, then benefits to making the commitment to a Splunk Enterprise License Agreement. Learn from one organization's successes and failures with adopting Splunk as a business critical product across the organization.","2015-09-22  17:00","{""name"":""Technology""}
{""name"":""Media and Entertainment""}","115-116 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""Jonathan Leghart"",""title"":""Systems Architect, Sony Network Entertainment International""}","2015-09-22","2015-09-22  16:15","From Diet to All You Can Eat: Growing to a Splunk Enterprise License Agreement",Adopting,"Adopting ","Breakout Session"
26,5,"Today's challenges in the multichannel-retail business are enormous. Especially for a company with a 66-year history that grew with the digitalization of this world and proudly still uses a mainframe for some tasks. 
Only a few platforms are able to successfully handle and monitor an extremely heterogeneous mix of hardware and software with the power to compute amounts of data no human alone can even begin to imagine. Today's business environment is more data-driven than ever before and needs constant adjustment to predict customer wishes and fulfill customer needs. To use Splunk successfully, you need a little structure in your definitions and some basic principles for your developers.
We will give you a glimpse of what has to be done to be able to monitor your business items from one end of your environment to the other. We also want to give you an idea of the benefits you will have as soon as you start implementing this structure and follow those principles.","2015-09-22  17:00","{""name"":""Retail""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""CIO""}","Good for All Skill Levels ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Andre Pietsch"",""title"":""Product Owner/Manager, Otto Group""}","2015-09-22","2015-09-22  16:15","End-to-End Business Transaction Monitoring with Splunk at Otto","Business Analytics","Business Analytics ","Breakout Session"
130,5,"At .conf2014 in Security Ninjutsu, we covered four real customer scenarios that allowed security users to leverage advanced correlation and anomaly detection, moving beyond basic incident response. You needn't have attended last year's session because this year we will cover four totally new use cases! We will be diving into analytics (basic through advanced) and threat discovery, easy apps for hunting, new bidirectional threat intel integrations and more! Through each of the examples, we will review the data sources, discuss how to analyze them, and see what actions could be taken, providing reusable examples for how to level up your security capabilities with Splunk software.","2015-09-22  17:00",,"119 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Intermediate ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""David Veuve"",""title"":""Sr. Sales Engineer, Splunk""}","2015-09-22","2015-09-22  16:15","Security Ninjutsu Part Two: More Security Analytics, Correlation and Action!","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
33,5,"You've taken the classes, you know how the product works, you've built dashboards, and you're proud of what you've created. Congratulations!  But you wonder, what more can be done? How can you make your spunk deployment more efficient? Can you provide greater end-to-end visibility? If you have asked yourself these questions, then this talk is for you.
In this hour, we'll dive into a specific use-case where the customer needed end-to-end visibility into the performance of the various online service offerings. You'll see how raw data gets turned into a handful of powerful dashboards that collectively provide visibility across the organization. Specifically, you'll learn how to employ statistically sound analytical methods to create searches and visualizations.
You'll learn how to leverage powerful drill down capabilities that feed information from one panel into another, allowing users to pivot through many views of the data.","2015-09-22  17:00",,"121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Best Practices""}","{""name"":""Pierre Brunel"",""title"":""Solutions Architect, Splunk""}","2015-09-22","2015-09-22  16:15","Building Powerful Analytics with Ease","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
38,5,"Splunk lookups are a powerful tool for data enrichment, but few users go beyond basic .csv or external lookups. Learn the strengths and limitations of different lookup types. Do you find time-based lookups confusing? Learn about sentinel values for tables, using lookups to speed up dashboards, and more. Step through the Lookup Glass into effective and different methods and use cases to get the most from your Splunk data.","2015-09-22  17:00",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}","Intermediate ","{""name"":""Best Practices""}
{""name"":""Customer Success Story""}","{""name"":""George Starcher"",""title"":""Senior Security Engineer, Defense Point Security""}
{""name"":""Duane Waddle"",""title"":""Senior Security Engineer, Defense Point Security""}","2015-09-22","2015-09-22  16:15","Beyond the Lookup Glass: Stepping Beyond Basic Lookups","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
34,5,"Want to build an amazing Splunk app but do not know where to start? Join us for a lap around the new Splunk Reference Apps, which provide end-to-end guidance on how to design, develop and deploy comprehensive Splunk solutions. These reference apps are complete, real-world apps built with our partners that are meant to showcase various capabilities of the Splunk developer platform as well as good and proven practices and patterns for building Splunk solutions. We'll demo a number of custom-built data providers (technical add-ons) and visualization widgets and discuss Design for Extensibility, CIM compliance, app configuration management, role-based security, app testing and packaging. The session will both challenge and inspire you! 
The session targets both novice and experienced Splunk app developers.

","2015-09-22  17:00",,"101-102 Panel Room ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Administrator""}","Good for All Skill Levels ",,"{""name"":""Grigori Melnik"",""title"":""Splunk Dev Platform Product Manager, Splunk""}","2015-09-22","2015-09-22  16:15","Accelerating your Solution Development with Splunk Reference Apps",Developing,"Using Splunk/Search Language ","Breakout Session"
117,4,"Bechtel Corporation is the largest construction and civil engineering company in the United States, ranking as the 4th-largest privately owned company in the United States. Since 1898, Bechtel has completed more than 25,000 extraordinary projects (many first-of-a-kind) in 160 countries on all seven continents serving the energy delivery; defense; environmental cleanup; mining and metals; oil, gas and chemicals; infrastructure and transportation; and telecommunications industries.  As such, Bechtel is a target-rich environment for a variety of cyber attacks and threats.
Since 2011, Bechtel has set out to build a world-class security operations center (SOC), which heavily relies on Splunk.  We will review several common security use cases and detail how we use Splunk within our operations. We will also discuss tricks that we developed to help ingest the large volume of indicators of compromise (IOCs) available from open source and paid threat intelligence feeds.","2015-09-22  15:45","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}
{""name"":""Public Sector""}","319 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}","{""name"":""Ryan Chapman"",""title"":""Incident Response Analyst, Bechtel""}
{""name"":""Lisa Tawfall"",""title"":""Network Security Monitoring Team Lead, Bechtel""}","2015-09-22","2015-09-22  15:00","Security Operations Use Cases at Bechtel","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
CT1,4,"A long, long time ago? in a university far, far away (from .conf2015 that is)? we installed Splunk. The University of Adelaide Information Security Team manages a Splunk deployment that has evolved to include a university-wide user base. When we started to think about Splunk outside of everyday working life, looking past our job description, we saw applications for machine data everywhere.
Come with me as I take you on our journey of evolution at the university that led to a light bulb moment. We're at a point in time now where people not only know about Splunk, but they proactively approach us with their challenges, from security operations to infrastructure operations, and on to web application monitoring and reporting. We have evolved to include Splunk software as part of facilities management reporting, teaching space usage and project reporting, and the best is yet to come. Importantly, while this talk comes out of a university, our experiences with Splunk are not entirely unique to higher education.","2015-09-22  15:45","{""name"":""Higher Education""}","Community Theater Marquee Ballroom ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""IoT and Industrial Data""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Mathew Benwell"",""title"":""Senior Information Security Specialist, The University of Adelaide""}","2015-09-22","2015-09-22  15:00","Splunking IT Data Is Great, Splunking Non-IT Data Is Awesome","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
18,4,"An efficient, reliable, and optimized supply chain is essential for retailers to achieve industry leading financial, operational, and customer satisfaction results. Technology is helping make everything in life a little bit easier and more efficient--including the process of shipping merchandise through a Distribution Center to a retailer?s store. It is no secret that many retailers are using robotic and automated warehouse technologies to assist with merchandise retrieval and order fulfillment. Robots and automated systems may help make a retailer?s life a little easier and more efficient, but automated technologies do not necessarily make a retailer optimized or reliable.
In this session, we will discuss how we have used Splunk Enterprise to analyze and gain insights from the machine data generated by the robotic and automated systems in Target?s Distribution Centers. We will discuss how Splunk Enterprise has enabled us to automate reporting and use predictive alerts and analytics to create a reliable and optimized Target supply chain. ","2015-09-22  15:45","{""name"":""Retail""}
{""name"":""Manufacturing""}","114 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""IoT and Industrial Data""}
{""name"":""Business Analytics""}
{""name"":""Customer Success Story""}","{""name"":""Alex Sneedmiller"",""title"":""Associate Engineer - Enterprise Services, Target""}
{""name"":""Adam McNeil"",""title"":""Automation Equipment Engineer, Target""}","2015-09-22","2015-09-22  15:00","Robotics Analytics at Target: Utilizing Machine Data from Robots to Provide Data-driven Insights and Decisions","Internet of Things","Internet of Things ","Breakout Session"
22,4,"Big Data, Big Data, Big Data. Is it just a buzzword or can we actually leverage it in a real world scenario?
In this session, we discuss and demonstrate the architecture that best encapsulates all the Big Data components and show how Splunk is ultimately the best choice for most use cases.
This session digs into the technical elements and architecture that is required to combine real-time data with historical data and transactional data. We demonstrate how Splunk, Hunk, DB Connect and Hadoop Connect can live under a single roof to enable analysts to combine Splunk, Hadoop and RDBMS.","2015-09-22  15:45",,"304-305 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}
{""name"":""Hunk""}","{""name"":""Architect""}
{""name"":""Developer""}","Intermediate ","{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}","{""name"":""Raanan Dagan"",""title"":""Sr Sales Engineer, Hadoop specialist, Splunk""}
{""name"":""Rohit Pujari"",""title"":""Big Data Specialist, Splunk""}","2015-09-22","2015-09-22  15:00","Real World Big Data Architecture - Splunk, Hadoop, RDBMS","Big Data","Big Data ","Breakout Session"
17,4,"Large enterprises often experience a variety of stability issues with their customer-facing applications which can adversely impact their customer centricity scores. At MetLife, we've been focusing on addressing these concerns over several years and found Splunk to be instrumental for a number of use cases. We started out with guerilla efforts which provided us with hands on experience to understand the variety of ways to use Splunk efficiently.
In this session, we will share our journey of taking the company focus on customer centricity and turning it into a strategic initiative from the ground up. You will be better informed of the accelerators as well as pitfalls as you mature your organization and usage of Splunk.","2015-09-22  15:45","{""name"":""Financial Services""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Customer Success Story""}","{""name"":""Mariya Gilyadova"",""title"":""Director, MetLife""}
{""name"":""Bob Jones"",""title"":""Sr. Software Development Engineer, MetLife""}","2015-09-22","2015-09-22  15:00","How MetLife is Using Splunk to Improve Customer Experience of Our Sales and Servicing Websites","Business Analytics","Business Analytics ","Breakout Session"
129,4,"Detecting fraud in government can be overwhelming due to the amount of data that needs to be managed. Most agencies have limited quality audit/control resources, making it difficult to gather transactional system data into a manageable subset to oversee program integrity.  But Splunk helped make the difference for the agency profiled in this session. Splunk is so flexible, they had the ability to integrate data sources without help of an application development team, and achieved cost savings because Splunk served as the one solution for security investigation, compliance reporting and program integrity issue detection. 
This session will show examples of internal threats where workers are overriding the system, as well as how to detect members of the same household receiving the same benefit. Join us to see how early detection can prevent fraud from happening and identify insider threats.

","2015-09-22  15:45","{""name"":""Technology""}
{""name"":""Public Sector""}","121 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Business Analytics""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Customer Success Story""}
{""name"":""Best Practices""}","{""name"":""Bharane Balasubramnaian"",""title"":""Manager, Deloitte Consulting""}","2015-09-22","2015-09-22  15:00","Exposing Fraud and Risk for Health Agencies","Security Compliance and Anti-fraud","Security,Compliance and Fraud ","Breakout Session"
24,4,"Fields are a critical component of Splunk, and they're necessary to be able to create reports, calculate statistics, correlate events and discover underlying structures and patterns. Come learn how to extract fields from events so that you can take your Splunking to the next level.
In this breakout session, you will learn how to use the field extractor, and by the end you will have learned how to extract fields from raw data and other fields, wrangle multi-valued fields, find and fix inappropriate extractions, and work some magic with the most underrated field of them all: punct!. (Elementary RegEx concepts will be covered but this will not be a course on RegEx.)","2015-09-22  15:45",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Best Practices""}","{""name"":""Clara Lee"",""title"":""Software Engineer, Splunk""}
{""name"":""Jesse Miller"",""title"":""Product Manager, Splunk""}","2015-09-22","2015-09-22  15:00","Field Extraction 101","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
19,4,"As Splunk becomes more critical to organizations and business functions, it becomes more important to maximize the uptime of the service. We'll talk about general principles of high availability and disaster recovery with Splunk software. We'll also discuss the various mechanisms for providing them, the levels of availability, relative advantages and costs of each of them.","2015-09-22  15:45",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}","Intermediate ",,"{""name"":""Dritan Bitincka"",""title"":""Principal Solutions Architect, Splunk""}","2015-09-22","2015-09-22  15:00","Architecting Splunk for High Availability and Disaster Recovery",Deploying,"Deploying ","Breakout Session"
15,3,"This session will deep-dive into the underlying technology of Splunk Cloud. We will outline the fundamentals of how we scale Splunk Cloud to ingest large volumes of data, dodge outages, and assure data durability. We will describe our robust monitoring infrastructure that uses our own Splunk Cloud cluster to analyze low level performance metrics and monitor for infrastructure outages. We will outline our robust security, hybrid visibility, disaster recovery and 100% uptime SLA. Come to this session to learn all the technical ins-and-outs of Splunk Cloud.","2015-09-22  13:45",,"117 (Level 1) ","{""name"":""Splunk Cloud""}","{""name"":""Operations Manager""}
{""name"":""Developer""}
{""name"":""Administrator""}","Intermediate ","{""name"":""Cloud Solutions""}
{""name"":""IT Operations""}
{""name"":""Application Delivery""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Rajiv Battula"",""title"":""Software Engineer, Splunk""}
{""name"":""Nikhil Mungel"",""title"":""Software Engineer, Splunk""}","2015-09-22","2015-09-22  13:00","Splunk Cloud--Technical Deep Dive",Cloud,"Cloud ","Breakout Session"
11,3,"It's important to get data into Splunk right the first time. This session will show you how to get the 'important' things right, the first time, sometimes using .conf files. Some of those important things to get right include timestamp and timezone, host extractions (which hosts to extract), sourcetype, line-breaking and index. Splunk's ""schema-on-the-fly"" allows flexibility in field extractions, but we need to index things properly to find the data. This presentation will walk customers through getting different data sources, e.g., logs, database, API calls (JIRA, SFDC), FIX data into Splunk with the correct parsing rules.","2015-09-22  13:45",,"111-112 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Architect""}
{""name"":""Administrator""}","Good for All Skill Levels ",,"{""name"":""Andrew Duca"",""title"":""Sr. Professional Services Consultant, Splunk""}","2015-09-22","2015-09-22  13:00","Onboarding Data Into Splunk",Deploying,"Deploying ","Breakout Session"
13,,,"2015-09-22  13:45",,"114 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-22","2015-09-22  13:00",,,"IT Operations ",
12,3,"Traditionally, Splunk software has been used to ingest and analyze machine-generated data. We, at the Northern Trust Bank, have extended this to ingest and analyze business transactions like cash movements in banking. This has provided us with powerful business capabilities like tracking transactions across multiple systems, calculating cash movement amounts, etc. It has also allowed us to predict business impact of certain unusual events, which has been very challenging in the past.
We have also been able to leverage the Splunk API calls to create a business-targeted application with a customized GUI interface.","2015-09-22  13:45","{""name"":""Financial Services""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Intermediate ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""IT Operations""}
{""name"":""Customer Success Story""}","{""name"":""Arijit Das"",""title"":""Senior Vice President, Technology Infrastructure and Operations, Northern Trust Bank""}
{""name"":""Joseph Noga"",""title"":""Vice President of Technology, Komodo Cloud""}","2015-09-22","2015-09-22  13:00","Leveraging Splunk for Tracking Business Transactions","Business Analytics","Business Analytics ","Breakout Session"
14,,,"2015-09-22  13:45",,"115-116 (Level 1) ",,,"Good for All Skill Levels ",,,"2015-09-22","2015-09-22  13:00",,,"Adopting ",
8,2,"The latest Splunk release provides breakthrough performance, capacity and management control; a new API for DevOps and IoT data collection; alert-based connectivity to business systems; and new features for large-scale data analysis. This session provides a brief overview of the entire feature set and helps you choose which drill-down sessions to attend.","2015-09-22  12:45",,"118 (Level 1) ","{""name"":""Splunk Enterprise""}
{""name"":""Splunk Cloud""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Advanced ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Business Analytics""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Kevin Faulkner"",""title"":""Product Marketing, Splunk""}
{""name"":""Mark Groves"",""title"":""Product Manager, Splunk""}","2015-09-22","2015-09-22  12:00","What's New for Splunk Enterprise and Cloud","Splunk Enterprise/What's New?","Splunk Enterprise/What’s New?! ","Breakout Session"
10,2,"You are a Splunk Ninja whose mission is to overcome the challenges of big data using Splunk. Splunk is supporting your cause with a repository of over 200 search commands, an expanding set of visualizations, REST endpoints, and SDKs. So which solutions are best suited for which problems?
In this discussion, we will explore real world use cases and explain how they were solved with common sense queries or perhaps some SPL trickery. Ever wondered how to format a number into dollars without losing your ability to sort or subtract with it later? What about plotting attacks on a map and coloring them according to severity? How about trying to find matches using data enrichments tools when the data doesn't completely match? You will leave this session with a set of tools for solving these examples and more.
You've been building queries, dashboards, and reports that have been blowing minds all over your company. Join us and we'll take your Splunk-titude to the next level.","2015-09-22  12:45",,"320 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Operations Manager""}
{""name"":""Administrator""}
{""name"":""Developer""}","Intermediate ","{""name"":""Best Practices""}","{""name"":""Jeff Champagne"",""title"":""Client Architect, Splunk""}
{""name"":""Kate Engel"",""title"":""Associate, Global Financial Services Organization""}","2015-09-22","2015-09-22  12:00","Smart Splunking","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
7,2,"Looking to archive data from Splunk?
Hunk 6.2.1 ships with a brand new archiver feature which lets you copy your Splunk data to cheaper storage, such as HDFS or S3, while keeping it searchable in-place. All configuration is done on the Search Head and works it with your existing Splunk indexers.
The new Bucket Reader allows any Hadoop-based application to read Splunk data buckets in their native format. Combined with  Hunk archiving functionality, this allows data added to Splunk indexes to continuously be made visible to 3rd-party tools such as Hive and Pig without the need for an export process. 
In this session, you will learn what Bucket Reader can and cannot do, and how to configure and use it. We will also show examples of how to write your own applications that read Hunk data. Finally, we will discuss how this lends flexibility to data workflows. 
Join this session to see the Splunk archiver in action, learn about how it works and how it differs from existing archiving techniques.","2015-09-22  12:45",,"304-305 (Level 3) ","{""name"":""Splunk Enterprise""}
{""name"":""Hunk""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Operations Manager""}","Intermediate ","{""name"":""Big Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Keith Schon"",""title"":""Principal Engineer, Hunk, Splunk""}
{""name"":""Theresa Vu"",""title"":""Director, Product Markeitng Big Data, Splunk""}","2015-09-22","2015-09-22  12:00","Archive Splunk Data and Access Using Hadoop Tools","Big Data","Big Data ","Breakout Session"
6,2,"The next version of Splunk is packed with new features targeting developers?from the new custom alert actions for triggering third-party systems, to the new HTTP Event Collector, to enhanced custom search command functionality. In this session, we?ll take a look at these new features and more, which are all in the box for enhancing your Splunk development.","2015-09-22  12:45",,"301-302 (Level 3) ","{""name"":""Splunk Enterprise""}","{""name"":""Developer""}","Good for All Skill Levels ","{""name"":""Application Delivery""}
{""name"":""Big Data""}
{""name"":""Cloud Solutions""}
{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}
{""name"":""Best Practices""}","{""name"":""Itay Neeman"",""title"":""Sr. Engineering Manager, Splunk""}
{""name"":""Glenn Block"",""title"":""Senior Product Manager, Splunk""}","2015-09-22","2015-09-22  12:00","A Lap Around Developer Awesomeness in the Next Version of Splunk",Developing,"Developing ","Breakout Session"
,,,"2015-09-22  12:45",,"Community Theater Marquee Ballroom ",,,,,,"2015-09-22","2015-09-22  12:00",,,"Developing ",
2,1,"In this session, we will cover interesting ways Splunk can be connected to industrial data, including the modular input framework, integration with messaging busses and partner products which solve specific device connectivity challenges. We'll talk about Splunk's extensible storage and analytics platforms, including the components and capabilities applicable to the advanced data science requirements of industrial OI applications.We'll also review Splunk's extensible user interfaces framework, including extensibility with JS/HTML5, third party visualization frameworks and partner products designed to solve specific UI requirements in industrial applications. ","2015-09-22  11:45","{""name"":""Energy and Utilities""}
{""name"":""Manufacturing""}","113 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}
{""name"":""Business Manager""}
{""name"":""CIO""}
{""name"":""CTO""}
{""name"":""CISO""}","Good for All Skill Levels ","{""name"":""IoT and Industrial Data""}
{""name"":""IT Operations""}
{""name"":""Log Management""}
{""name"":""Security Compliance and Anti-fraud""}","{""name"":""Brian Gilmore"",""title"":""Solutions Marketing Manager, IOT, Splunk""}","2015-09-22","2015-09-22  11:00","Splunk as a Platform for Operational Intelligence for SCADA and Other Industrial Systems","Internet of Things","Internet of Things ","Breakout Session"
3,1,"Whether you're a n00b, an architect or anywhere in-between, you've probably Splunked something and thought ""There's gotta be a better way to do this."" Learn those better ways at this session as we explore best practices for everything Splunk. Attendees are invited to think critically and strengthen best practices into the bestest practices!","2015-09-22  11:45",,"114 (Level 1) ","{""name"":""Splunk Enterprise""}","{""name"":""Administrator""}
{""name"":""Architect""}
{""name"":""Developer""}
{""name"":""Operations Manager""}
{""name"":""Security Analyst""}","Good for All Skill Levels ","{""name"":""Best Practices""}","{""name"":""Burch Simon"",""title"":""Solutions Architect, Splunk""}","2015-09-22","2015-09-22  11:00","Best Practices and Better Practices","Using Splunk/Search Language","Using Splunk/Search Language ","Breakout Session"
1,1,"Learn the basics of how to build out your Splunk deployment. You will learn about specific Splunk roles and how they are applied in practice. The process for building/expanding a Splunk installation will be covered in addition to best practices.","2015-09-22  11:45",,"111-112 (Level 1) ",,"{""name"":""Architect""}
{""name"":""Administrator""}","Good for All Skill Levels ","{""name"":""Best Practices""}","{""name"":""Simeon Yep"",""title"":""Sr. Solutions Architect, Splunk""}
{""name"":""Karandeep Bains"",""title"":""Sales Engineering Manager, Splunk""}","2015-09-22","2015-09-22  11:00","Architecting and Sizing Your Splunk Deployment",Deploying,"Deploying ","Breakout Session"
